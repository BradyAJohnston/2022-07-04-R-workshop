[
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "Centre for Applied Bioinformatics R Workshop",
    "section": "",
    "text": "Data Carpentry is an open source project, and we welcome contributions of all kinds: new lessons, fixes to existing material, bug reports, and reviews of proposed changes are all welcome.\n\nBy contributing, you agree that we may redistribute your work under our license. In exchange, we will address your issues and/or assess your change proposal as promptly as we can, and help you become a member of our community. Everyone involved in Software Carpentry and Data Carpentry agrees to abide by our code of conduct.\n\n\nIf you have an idea about how to improve the lesson, you can submit it as an issue on GitHub. If you have multiple unrelated suggestions, it is best to open a separate issue for each of them. This makes it easier for the project maintainers to discuss and resolve them.\nSubmitting an issue can count as a contribution for your instructor training checkout. If your contribution is for instructor training, send an email with a link to the issue to checkout@carpentries.org. Please note that it is not necessary to point out in the issue‚Äôs title or text that it is a contribution for the instructor training checkout.\n\nYou can also suggest changes by modifying the lesson code directly and submitting your changes as a pull request.\n\nFork the datacarpentry/R-ecology-lesson repository on GitHub. See the ‚ÄúFork‚Äù button in the top-right corner of the screen on the GitHub website.\n\nClone that repository to your own machine. (It is also possible to make minor edits right on GitHub.) At your terminal:\ngit clone https://github.com/your_username/R-ecology-lesson.git R-ecology-lesson\ncd R-ecology-lesson\ngit remote add upstream https://github.com/datacarpentry/R-ecology-lesson.git\n\n\nCreate a branch from main for your changes. Give your branch a meaningful name, such as fix-typos-dplyr-lesson or add-tutorial-on-visualization. At your terminal:\ngit checkout -b fix-typos-dplyr-lesson\n\n\nMake your changes to the Rmd file. If you‚Äôd like to check the rendered version of your changes, you can do one of three things:\n\nif you have GNU Make installed on your system, type make at your shell terminal.\nif you use RStudio, click on the ‚ÄúKnit‚Äù button in the top-right corner of your editor pane.\nin other cases, you can type: rmarkdown::render_site(\"01-intro-to-r.Rmd\") in your R terminal (make sure your working directory is at the root of the lesson) to generate the corresponding html file.\n\n\nCommit the Rmd file you edited (git add file-you-changed.Rmd, followed by git commit -m \"fix typos in dplyr lesson\"), and push your changes to your repository on GitHub (git push origin fix-typos-dplyr-lesson). If your change affects a lesson, please only commit and push the Rmd files. The rendered versions will be generated by the lesson maintainers to avoid merge conflicts.\nSend a pull request (PR) to the main branch of the datacarpentry/R-ecology-lesson repository for this lesson at https://github.com/datacarpentry/R-ecology-lesson\n\nIf you are new to Git or GitHub, software like GitHub Desktop can make this process easier for you.\nIf it is easier for you to send edits to us some other way, please mail us at checkout@carpentries.org. Given a choice between you creating content or wrestling with Git, we‚Äôd rather have you doing the former.\n\n\nFor the R material, lessons are written in RMarkdown (files ending in Rmd). Filenames follow the pattern 00-before-we-start.Rmd, 01-intro-to-r.Rmd and so on. That is, we use two digits followed by a topic key to ensure files appear in the right order when listed.\nA Makefile converts the Rmd files into HTML files that are processed by Jekyll (the tool GitHub uses to create websites) as explained in the README file.\nTo ensure a consistent formatting of the lessons, we recommend the following formatting guidelines for RMarkdown files:\n\nNo trailing white space\nWrap lines at 80 characters (unless it breaks URLs)\nUse consistent capitalization (e.g., R not r, RStudio not rstudio or Rstudio)\nFunction names are written as function() while variables are written as variable, and package names as package.\nUse unclosed atx style headers (see below):\n\n## Use this format for headers\n\nAnd not this format\n-------------------\n\nMost R code within .Rmd files is written inside of code chunks. Code chunks can have a name and a number of options, but neither is required. Options are added to a code chunk like this:\n```{r, chunk_name, option1 = value, option2 = value, ...}\nThroughout the lesson, we use different code chunk options, mostly to change when and how the code in the chunks is being executed. Below you will find a list of the most common options we use and information on how we use them. More information on RMarkdown code chunk options can be found here. When in doubt, consult the Rmd files for examples.\n\nThe answer option is used in challenges to hide the content of the chunk so that the reader needs to interact with the website to reveal it. The default value is FALSE.\n\nIf echo = FALSE, the code will be executed and its output will be visible on the lesson website (unless specified otherwise by the eval, message, or results options), but the code itself will not be visible. This is useful when writing code for the code handout, because it allows to include redundant headings and comments that are not needed in the lesson itself, but help to structure and clarify the code handout. The default value is TRUE.\n\nIf eval = FALSE the code in the chunk will not be executed by R when the file is processed to create the lesson website. Accordingly, no output will be created. This is useful, for example, when seeing the result of the code is not required for the lesson, or when the code chunk contains code that installs or loads packages, downloads files, or opens the R help window. The default value is TRUE.\n\nIf FALSE messages produced by the code will not be shown. THis is useful, for example when loading packages like tidyverse that output when loaded. By using message = FALSE, such output can be hidden. The default value is TRUE.\n\nCode chunks that have the option purl = TRUE will be included in the code handout (see below). The default value is FALSE.\n\nDetermines if and how the text output of a code chunk is formatted. Useful values are markup (to format text output using markup, usually formatting it as a code block), asis (to write raw output directly into the document without any markup), and hide (to hide the output, for example when loading data sets).\n\nThe code handout code-handout.R contains code that can be distributed to learners. This is particularly useful for error prone code such as long URLs for downloading files. The code handout is created automatically from the lesson‚Äôs .Rmd files by make_code_handout.R, and we use the purl() function from knitr to\ncreate the handout. Code that should be included in the code handout must be enclosed in an R code chunk with the chunk option purl = TRUE (see above). To make the handout more useful, consider including explanatory comments.\n\nWe don‚Äôt store data for lessons inside the lesson repositories. For completed lessons the data should be publicly available in a data repository appropriate to the data type. For lesson development the data may be provided in any way that is convenient including posting to a website, on figshare, a public Dropbox link, a GitHub gist, or even included in the pull request (PR). Once the PR is ready to merge the data should be placed in the official data repository and all links to the data updated.\nRaw data go into data_raw/. However, at this stage, this folder is created programmatically and only contain dataset downloaded directly from the Figshare repository. In other words, it can be safely be deleted (e.g.¬†using make clean-data or make clean.)\nThe data/ folder only contains data generated/exported by R code.\n\nImages (e.g., screenshots) are stored in the img/ folder. Graphics generated by some R code also go into this folder and get the prefix R-ecology-. This latter case is handled automatically with some knitr options in the setup.R file.\n\nThe site_libs folder is generated by the rmarkdown package and holds the javascript, css, and fonts used by the website.\nWe aim to have our lessons be as self-contained as possible. Images and other external resources should be included in the repository whenever possible.\n\n\n\nWhere can I get help?  Mail us at team@carpentries.org or come chat with us on Slack.\n\n\nPage built on: üìÜ 2022-06-28 ‚Äí üï¢ 17:21:57"
  },
  {
    "objectID": "05-r-and-databases.html#introduction",
    "href": "05-r-and-databases.html#introduction",
    "title": "SQL databases and R",
    "section": "Introduction",
    "text": "Introduction\nSo far, we have dealt with small datasets that easily fit into your computer‚Äôs memory. But what about datasets that are too large for your computer to handle as a whole? In this case, storing the data outside of R and organizing it in a database is helpful. Connecting to the database allows you to retrieve only the chunks needed for the current analysis.\nEven better, many large datasets are already available in public or private databases. You can query them without having to download the data first.\nR can connect to almost any existing database type. Most common database types have R packages that allow you to connect to them (e.g., RSQLite, RMySQL, etc). Furthermore, the dplyr package you used in the previous chapter, in conjunction with dbplyr supports connecting to the widely-used open source databases sqlite, mysql and postgresql, as well as Google‚Äôs bigquery, and it can also be extended to other database types (a vignette in the dplyr package explains how to do it). RStudio has created a website that provides documentation and best practices to work on database interfaces.\nInterfacing with databases using dplyr focuses on retrieving and analyzing datasets by generating SELECT SQL statements, but it doesn‚Äôt modify the database itself. dplyr does not offer functions to UPDATE or DELETE entries. If you need these functionalities, you will need to use additional R packages (e.g., RSQLite). Here we will demonstrate how to interact with a database using dplyr, using both the dplyr‚Äôs verb syntax and the SQL syntax.\nThe portal_mammals database\nWe will continue to explore the surveys data you are already familiar with from previous lessons. First, we are going to install the dbplyr package:\n\ninstall.packages(c(\"dbplyr\", \"RSQLite\"))\n\nThe SQLite database is contained in a single file portal_mammals.sqlite that you generated during the SQL lesson. If you don‚Äôt have it, you can download it from Figshare into the data_raw subdirectory using:\n\ndir.create(\"data_raw\", showWarnings = FALSE)\ndownload.file(url = \"https://ndownloader.figshare.com/files/2292171\",\n              destfile = \"data_raw/portal_mammals.sqlite\", mode = \"wb\")"
  },
  {
    "objectID": "05-r-and-databases.html#connecting-to-databases",
    "href": "05-r-and-databases.html#connecting-to-databases",
    "title": "SQL databases and R",
    "section": "Connecting to databases",
    "text": "Connecting to databases\nWe can point R to this database using:\n\nlibrary(dplyr)\nlibrary(dbplyr)\n\n#> \n#> Attaching package: 'dbplyr'\n\n\n#> The following objects are masked from 'package:dplyr':\n#> \n#>     ident, sql\n\nmammals <- DBI::dbConnect(RSQLite::SQLite(), \"data_raw/portal_mammals.sqlite\")\n\nThis command uses 2 packages that helps dbplyr and dplyr talk to the SQLite database. DBI is not something that you‚Äôll use directly as a user. It allows R to send commands to databases irrespective of the database management system used. The RSQLite package allows R to interface with SQLite databases.\nThis command does not load the data into the R session (as the read_csv() function did). Instead, it merely instructs R to connect to the SQLite database contained in the portal_mammals.sqlite file.\nUsing a similar approach, you could connect to many other database management systems that are supported by R including MySQL, PostgreSQL, BigQuery, etc.\nLet‚Äôs take a closer look at the mammals database we just connected to:\n\nsrc_dbi(mammals)\n\n#> src:  sqlite 3.38.5 [/Users/brady/git/rworkshop/2022-07-04-R-workshop/data_raw/portal_mammals.sqlite]\n#> tbls: plots, species, surveys\n\n\nJust like a spreadsheet with multiple worksheets, a SQLite database can contain multiple tables. In this case three of them are listed in the tbls row in the output above:\n\nplots\nspecies\nsurveys\n\nNow that we know we can connect to the database, let‚Äôs explore how to get the data from its tables into R.\nQuerying the database with the SQL syntax\nTo connect to tables within a database, you can use the tbl() function from dplyr. This function can be used to send SQL queries to the database. To demonstrate this functionality, let‚Äôs select the columns ‚Äúyear‚Äù, ‚Äúspecies_id‚Äù, and ‚Äúplot_id‚Äù from the surveys table:\n\ntbl(mammals, sql(\"SELECT year, species_id, plot_id FROM surveys\"))\n\nWith this approach you can use any of the SQL queries we have seen in the database lesson.\nQuerying the database with the dplyr syntax\nOne of the strengths of dplyr is that the same operation can be done using dplyr‚Äôs verbs instead of writing SQL. First, we select the table on which to do the operations by creating the surveys object, and then we use the standard dplyr syntax as if it were a data frame:\n\nsurveys <- tbl(mammals, \"surveys\")\nsurveys %>%\n    select(year, species_id, plot_id)\n\nIn this case, the surveys object behaves like a data frame. Several functions that can be used with data frames can also be used on tables from a database. For instance, the head() function can be used to check the first 10 rows of the table:\n\nhead(surveys, n = 10)\n\n#> # Source:   SQL [10 x 9]\n#> # Database: sqlite 3.38.5 [/Users/brady/git/rworkshop/2022-07-04-R-workshop/data_raw/portal_mammals.sqlite]\n#>    record_id month   day  year plot_id species_id sex   hindfoot_length weight\n#>        <int> <int> <int> <int>   <int> <chr>      <chr>           <int>  <int>\n#>  1         1     7    16  1977       2 NL         M                  32     NA\n#>  2         2     7    16  1977       3 NL         M                  33     NA\n#>  3         3     7    16  1977       2 DM         F                  37     NA\n#>  4         4     7    16  1977       7 DM         M                  36     NA\n#>  5         5     7    16  1977       3 DM         M                  35     NA\n#>  6         6     7    16  1977       1 PF         M                  14     NA\n#>  7         7     7    16  1977       2 PE         F                  NA     NA\n#>  8         8     7    16  1977       1 DM         M                  37     NA\n#>  9         9     7    16  1977       1 DM         F                  34     NA\n#> 10        10     7    16  1977       6 PF         F                  20     NA\n\n\nThis output of the head command looks just like a regular data.frame: The table has 9 columns and the head() command shows us the first 10 rows. Note that the columns plot_type, taxa, genus, and species are missing. These are now located in the tables plots and species which we will join together in a moment.\nHowever, some functions don‚Äôt work quite as expected. For instance, let‚Äôs check how many rows there are in total using nrow():\n\nnrow(surveys)\n\n#> [1] NA\n\n\nThat‚Äôs strange - R doesn‚Äôt know how many rows the surveys table contains - it returns NA instead. You might have already noticed that the first line of the head() output included ?? indicating that the number of rows wasn‚Äôt known.\nThe reason for this behavior highlights a key difference between using dplyr on datasets in memory (e.g.¬†loaded into your R session via read_csv()) and those provided by a database. To understand it, we take a closer look at how dplyr communicates with our SQLite database.\nSQL translation\nRelational databases typically use a special-purpose language, Structured Query Language (SQL), to manage and query data.\nFor example, the following SQL query returns the first 10 rows from the surveys table:\nSELECT *\nFROM `surveys`\nLIMIT 10\nBehind the scenes, dplyr:\n\ntranslates your R code into SQL\nsubmits it to the database\ntranslates the database‚Äôs response into an R data frame\n\nTo lift the curtain, we can use dplyr‚Äôs show_query() function to show which SQL commands are actually sent to the database:\n\nshow_query(head(surveys, n = 10))\n\nThe output shows the actual SQL query sent to the database; it matches our manually constructed SELECT statement above.\nInstead of having to formulate the SQL query ourselves - and having to mentally switch back and forth between R and SQL syntax - we can delegate this translation to dplyr. (You don‚Äôt even need to know SQL to interact with a database via dplyr!)\ndplyr, in turn, doesn‚Äôt do the real work of subsetting the table, either. Instead, it merely sends the query to the database, waits for its response and returns it to us.\nThat way, R never gets to see the full surveys table - and that‚Äôs why it could not tell us how many rows it contains. On the bright side, this allows us to work with large datasets - even too large to fit into our computer‚Äôs memory.\ndplyr can translate many different query types into SQL allowing us to, e.g., select() specific columns, filter() rows, or join tables.\nTo see this in action, let‚Äôs compose a few queries with dplyr."
  },
  {
    "objectID": "05-r-and-databases.html#simple-database-queries",
    "href": "05-r-and-databases.html#simple-database-queries",
    "title": "SQL databases and R",
    "section": "Simple database queries",
    "text": "Simple database queries\nFirst, let‚Äôs only request rows of the surveys table in which weight is less than 5 and keep only the species_id, sex, and weight columns.\n\nsurveys %>%\n  filter(weight < 5) %>%\n  select(species_id, sex, weight)\n\n#> # Source:   SQL [?? x 3]\n#> # Database: sqlite 3.38.5 [/Users/brady/git/rworkshop/2022-07-04-R-workshop/data_raw/portal_mammals.sqlite]\n#>    species_id sex   weight\n#>    <chr>      <chr>  <int>\n#>  1 PF         M          4\n#>  2 PF         F          4\n#>  3 PF         <NA>       4\n#>  4 PF         F          4\n#>  5 PF         F          4\n#>  6 RM         M          4\n#>  7 RM         F          4\n#>  8 RM         M          4\n#>  9 RM         M          4\n#> 10 RM         M          4\n#> # ‚Ä¶ with more rows\n\n\nExecuting this command will return a table with 10 rows and the requested species_id, sex and weight columns. Great!\n‚Ä¶ but wait, why are there only 10 rows?\nThe last line:\n# ... with more rows\nindicates that there are more results that fit our filtering criterion. Why was R lazy and only retrieved 10 of them?"
  },
  {
    "objectID": "05-r-and-databases.html#laziness",
    "href": "05-r-and-databases.html#laziness",
    "title": "SQL databases and R",
    "section": "Laziness",
    "text": "Laziness\nHadley Wickham, the author of dplyr explains:\n\nWhen working with databases, dplyr tries to be as lazy as possible:\n\nIt never pulls data into R unless you explicitly ask for it.\nIt delays doing any work until the last possible moment - it collects together everything you want to do and then sends it to the database in one step.\n\n\nWhen you construct a dplyr query, you can connect multiple verbs into a single pipeline. For example, we combined the filter() and select() verbs using the %>% pipe.\nIf we wanted to, we could add on even more steps, e.g.¬†remove the sex column in an additional select call:\n\ndata_subset <- surveys %>%\n  filter(weight < 5) %>%\n  select(species_id, sex, weight)\n\ndata_subset %>%\n  select(-sex)\n\n#> # Source:   SQL [?? x 2]\n#> # Database: sqlite 3.38.5 [/Users/brady/git/rworkshop/2022-07-04-R-workshop/data_raw/portal_mammals.sqlite]\n#>    species_id weight\n#>    <chr>       <int>\n#>  1 PF              4\n#>  2 PF              4\n#>  3 PF              4\n#>  4 PF              4\n#>  5 PF              4\n#>  6 RM              4\n#>  7 RM              4\n#>  8 RM              4\n#>  9 RM              4\n#> 10 RM              4\n#> # ‚Ä¶ with more rows\n\n\nJust like the first select(species_id, sex, weight) call, the select(-sex) command is not executed by R. It is sent to the database instead. Only the final result is retrieved and displayed to you.\nOf course, we could always add on more steps, e.g., we could filter by species_id or minimum weight. That‚Äôs why R doesn‚Äôt retrieve the full set of results - instead it only retrieves the first 10 results from the database by default. (After all, you might want to add an additional step and get the database to do more work‚Ä¶)\nTo instruct R to stop being lazy, e.g.¬†to retrieve all of the query results from the database, we add the collect() command to our pipe. It indicates that our database query is finished: time to get the final results and load them into the R session.\n\ndata_subset <- surveys %>%\n  filter(weight < 5) %>%\n  select(species_id, sex, weight) %>%\n  collect()\n\nNow we have all 17 rows that match our query in a data.frame and can continue to work with them exclusively in R, without communicating with the database."
  },
  {
    "objectID": "05-r-and-databases.html#complex-database-queries",
    "href": "05-r-and-databases.html#complex-database-queries",
    "title": "SQL databases and R",
    "section": "Complex database queries",
    "text": "Complex database queries\ndplyr enables database queries across one or multiple database tables, using the same single- and multiple-table verbs you encountered previously. This means you can use the same commands regardless of whether you interact with a remote database or local dataset! This is a really useful feature if you work with large datasets: you can first prototype your code on a small subset that fits into memory, and when your code is ready, you can change the input dataset to your full database without having to change the syntax.\nOn the other hand, being able to use SQL queries directly can be useful if your collaborators have already put together complex queries to prepare the dataset that you need for your analysis.\nTo illustrate how to use dplyr with these complex queries, we are going to join the plots and surveys tables. The plots table in the database contains information about the different plots surveyed by the researchers. To access it, we point the tbl() command to it:\n\nplots <- tbl(mammals, \"plots\")\nplots\n\n#> # Source:   table<plots> [?? x 2]\n#> # Database: sqlite 3.38.5 [/Users/brady/git/rworkshop/2022-07-04-R-workshop/data_raw/portal_mammals.sqlite]\n#>    plot_id plot_type                \n#>      <int> <chr>                    \n#>  1       1 Spectab exclosure        \n#>  2       2 Control                  \n#>  3       3 Long-term Krat Exclosure \n#>  4       4 Control                  \n#>  5       5 Rodent Exclosure         \n#>  6       6 Short-term Krat Exclosure\n#>  7       7 Rodent Exclosure         \n#>  8       8 Control                  \n#>  9       9 Spectab exclosure        \n#> 10      10 Rodent Exclosure         \n#> # ‚Ä¶ with more rows\n\n\nThe plot_id column also features in the surveys table:\n\nsurveys\n\n#> # Source:   table<surveys> [?? x 9]\n#> # Database: sqlite 3.38.5 [/Users/brady/git/rworkshop/2022-07-04-R-workshop/data_raw/portal_mammals.sqlite]\n#>    record_id month   day  year plot_id species_id sex   hindfoot_length weight\n#>        <int> <int> <int> <int>   <int> <chr>      <chr>           <int>  <int>\n#>  1         1     7    16  1977       2 NL         M                  32     NA\n#>  2         2     7    16  1977       3 NL         M                  33     NA\n#>  3         3     7    16  1977       2 DM         F                  37     NA\n#>  4         4     7    16  1977       7 DM         M                  36     NA\n#>  5         5     7    16  1977       3 DM         M                  35     NA\n#>  6         6     7    16  1977       1 PF         M                  14     NA\n#>  7         7     7    16  1977       2 PE         F                  NA     NA\n#>  8         8     7    16  1977       1 DM         M                  37     NA\n#>  9         9     7    16  1977       1 DM         F                  34     NA\n#> 10        10     7    16  1977       6 PF         F                  20     NA\n#> # ‚Ä¶ with more rows\n\n\nBecause plot_id is listed in both tables, we can use it to look up matching records, and join the two tables.\nIf we have two tables named x and y with a common column called ‚ÄúID‚Äù, we can join them using ‚Äòjoin‚Äô functions, two of which are described and illustrated below.\n\ninner_join() : This returns all rows from x where there are matching values in y, and all columns from x and y.\nleft_join() : This return all rows from x, and all columns from x and y. Rows in x with no match in y will have NA values in the new columns.\n\nIn both forms of join, if there are multiple matches between x and y, all combinations of the matches are returned. For the full list of ‚Äòjoin‚Äô functions, check out the tidyverse join page.\nIn our example, the two tables we want to join are ‚Äòplots‚Äô and ‚Äòsurveys‚Äô.\n\n\ndiagram illustrating inner and left joins\n\n\nFor example, to extract all surveys for the first plot, which has plot_id 1, we can do:\n\nplots %>%\n  filter(plot_id == 1) %>%\n  inner_join(surveys) %>%\n  collect()\n\n#> Joining, by = \"plot_id\"\n\n\n#> # A tibble: 1,995 √ó 10\n#>    plot_id plot_type         record_id month   day  year species_id sex  \n#>      <int> <chr>                 <int> <int> <int> <int> <chr>      <chr>\n#>  1       1 Spectab exclosure         6     7    16  1977 PF         M    \n#>  2       1 Spectab exclosure         8     7    16  1977 DM         M    \n#>  3       1 Spectab exclosure         9     7    16  1977 DM         F    \n#>  4       1 Spectab exclosure        78     8    19  1977 PF         M    \n#>  5       1 Spectab exclosure        80     8    19  1977 DS         M    \n#>  6       1 Spectab exclosure       218     9    13  1977 PF         M    \n#>  7       1 Spectab exclosure       222     9    13  1977 DS         M    \n#>  8       1 Spectab exclosure       239     9    13  1977 DS         M    \n#>  9       1 Spectab exclosure       263    10    16  1977 DM         M    \n#> 10       1 Spectab exclosure       270    10    16  1977 DM         F    \n#> # ‚Ä¶ with 1,985 more rows, and 2 more variables: hindfoot_length <int>,\n#> #   weight <int>\n\n\nImportant Note: Without the collect() statement, only the first 10 matching rows are returned. By adding collect(), the full set of 1,985 is retrieved.\n\nChallenge\nWrite a query that returns the number of rodents observed in each plot in each year.\nHint: Connect to the species table and write a query that joins the species and survey tables together to exclude all non-rodents. The query should return counts of rodents by year.\nOptional: Write a query in SQL that will produce the same result. You can join multiple tables together using the following syntax where foreign key refers to your unique id (e.g., species_id):\nSELECT table.col, table.col\nFROM table1 JOIN table2\nON table1.key = table2.key\nJOIN table3 ON table2.key = table3.key\n\n\n\nAnswer\n\n\n## with dplyr syntax\nspecies <- tbl(mammals, \"species\")\n\nleft_join(surveys, species) %>%\n  filter(taxa == \"Rodent\") %>%\n  group_by(taxa, year, plot_id) %>%\n  tally() %>%\n  collect()\n\n#> Joining, by = \"species_id\"\n\n## with SQL syntax\nquery <- paste(\"\nSELECT a.year, b.taxa,count(*) as count\nFROM surveys a\nJOIN species b\nON a.species_id = b.species_id\nAND b.taxa = 'Rodent'\nGROUP BY b.taxa, a.year, a.plot_id\",\nsep = \"\" )\n\ntbl(mammals, sql(query))\n\n\n\n\n\n\n\n\nChallenge\nWrite a query that returns the total number of rodents in each genus caught in the different plot types.\nHint: Write a query that joins the species, plot, and survey tables together. The query should return counts of genus by plot type.\n\n\n\nAnswer\n\n\nspecies <- tbl(mammals, \"species\")\ngenus_counts <- left_join(surveys, plots) %>%\n  left_join(species) %>%\n  filter(taxa == \"Rodent\") %>%\n  group_by(plot_type, genus) %>%\n  tally() %>%\n  collect()\n\n\n\n\n\n\n\nThis is useful if we are interested in estimating the number of individuals belonging to each genus found in each plot type. But what if we were interested in the number of genera found in each plot type? Using tally() gives the number of individuals, instead we need to use n_distinct() to count the number of unique values found in a column.\n\nspecies <- tbl(mammals, \"species\")\nunique_genera <- left_join(surveys, plots) %>%\n    left_join(species) %>%\n    group_by(plot_type) %>%\n    summarize(\n        n_genera = n_distinct(genus)\n    ) %>%\n    collect()\n\n#> Joining, by = \"plot_id\"\n#> Joining, by = \"species_id\"\n\n\nn_distinct, like the other dplyr functions we have used in this lesson, works not only on database connections but also on regular data frames."
  },
  {
    "objectID": "05-r-and-databases.html#creating-a-new-sqlite-database",
    "href": "05-r-and-databases.html#creating-a-new-sqlite-database",
    "title": "SQL databases and R",
    "section": "Creating a new SQLite database",
    "text": "Creating a new SQLite database\nSo far, we have used a previously prepared SQLite database. But we can also use R to create a new database, e.g.¬†from existing csv files. Let‚Äôs recreate the mammals database that we‚Äôve been working with, in R. First let‚Äôs download and read in the csv files. We‚Äôll import tidyverse to gain access to the read_csv() function.\n\ndownload.file(\"https://ndownloader.figshare.com/files/3299483\",\n              \"data_raw/species.csv\")\ndownload.file(\"https://ndownloader.figshare.com/files/10717177\",\n              \"data_raw/surveys.csv\")\ndownload.file(\"https://ndownloader.figshare.com/files/3299474\",\n              \"data_raw/plots.csv\")\nlibrary(tidyverse)\nspecies <- read_csv(\"data_raw/species.csv\")\n\n#> Rows: 54 Columns: 4\n#> ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#> Delimiter: \",\"\n#> chr (4): species_id, genus, species, taxa\n#> \n#> ‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n#> ‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsurveys <- read_csv(\"data_raw/surveys.csv\")\n\n#> Rows: 35549 Columns: 9\n#> ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#> Delimiter: \",\"\n#> chr (2): species_id, sex\n#> dbl (7): record_id, month, day, year, plot_id, hindfoot_length, weight\n#> \n#> ‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n#> ‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nplots <- read_csv(\"data_raw/plots.csv\")\n\n#> Rows: 24 Columns: 2\n#> ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#> Delimiter: \",\"\n#> chr (1): plot_type\n#> dbl (1): plot_id\n#> \n#> ‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n#> ‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAlso, you can create new SQLite database with dplyr by adding an argument to the same command we used above to open an existing .sqlite file. The create = TRUE argument instructs R to create a new, empty database instead.\nCaution: When create = TRUE is added, any existing database at the same location is overwritten without warning.\n\nmy_db_file <- \"data/portal-database-output.sqlite\"\nmy_db <- src_sqlite(my_db_file, create = TRUE)\n\n#> Warning: `src_sqlite()` was deprecated in dplyr 1.0.0.\n#> Please use `tbl()` directly with a database connection\n#> This warning is displayed once every 8 hours.\n#> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\n\n\nCurrently, our new database is empty, it doesn‚Äôt contain any tables:\n\nmy_db\n\n#> src:  sqlite 3.38.5 [/Users/brady/git/rworkshop/2022-07-04-R-workshop/data/portal-database-output.sqlite]\n#> tbls:\n\n\nTo add tables, we copy the existing data.frames into the database one by one:\n\ncopy_to(my_db, surveys)\ncopy_to(my_db, plots)\nmy_db\n\nIf you check the location of our database you‚Äôll see that data is automatically being written to disk. R and dplyr not only provide ways to query existing databases, they also provide functionality to create your own databases from flat files!\n\nChallenge\nAdd the remaining species table to the my_db database and run some of your queries from earlier in the lesson to verify that you have faithfully recreated the mammals database.\n\n\n\n\nNote: In this example, we first loaded all of the data into the R session by reading the three csv files. Because all the data has to flow through R, this is not suitable for very large datasets.\nNote: Finally, to close the connection to the mammals database you may use DBI::dbDisconnect(mammals); this discards all pending work and frees resources, e.g.¬†memory.\n\nPage built on: üìÜ 2022-06-28 ‚Äí üï¢ 17:22:11"
  },
  {
    "objectID": "reference.html",
    "href": "reference.html",
    "title": "Centre for Applied Bioinformatics R Workshop",
    "section": "",
    "text": "Cheat sheet of functions used in the lessons"
  },
  {
    "objectID": "reference.html#lesson-1-introduction-to-r",
    "href": "reference.html#lesson-1-introduction-to-r",
    "title": "Centre for Applied Bioinformatics R Workshop",
    "section": "Lesson 1 ‚Äì Introduction to R",
    "text": "Lesson 1 ‚Äì Introduction to R\n\nsqrt() # calculate the square root\nround() # round a number\nargs() # find what arguments a function takes\nlength() # how many elements are in a particular vector\nclass() # the class (the type of element) of an object\nstr() # an overview of the object and the elements it contains\nc() # create vector; add elements to vector\n[  ] # extract and subset vector\n%in% # to test if a value is found in a vector\nis.na() # test if there are missing values\nna.omit() # Returns the object with incomplete cases removed\ncomplete.cases()# elements which are complete cases"
  },
  {
    "objectID": "reference.html#lesson-2-starting-with-data",
    "href": "reference.html#lesson-2-starting-with-data",
    "title": "Centre for Applied Bioinformatics R Workshop",
    "section": "Lesson 2 ‚Äì Starting with data",
    "text": "Lesson 2 ‚Äì Starting with data\n\ndownload.file() # download files from the internet to your computer\nread_csv() # load CSV file into R memory\nhead() # shows the first 6 rows\nview() # invoke a spreadsheet-style data viewer\nread_delim() # load a file in table format into R memory\nstr() # check structure of the object and information about the class, length and content of each column\ndim() # check dimension of data frame\nnrow() # returns the number of rows\nncol() # returns the number of columns\ntail() # shows the last 6 rows\nnames() # returns the column names (synonym of colnames() for data frame objects)\nrownames() # returns the row names\nsummary() # summary statistics for each column\nfactor() # create factors\nlevels() # check levels of a factor\nnlevels() # check number of levels of a factor\nas.character() # convert an object to a character vector\nas.numeric() # convert an object to a numeric vector\nas.numeric(as.character(x)) # convert factors where the levels appear as characters to a numeric vector\nas.numeric(levels(x))[x] # convert factors where the levels appear as numbers to a numeric vector\nplot() # plot an object\naddNA() # convert NA into a factor level\ndata.frame() # create a data.frame object\nymd() # convert a vector representing year, month, and day to a Date vector\npaste() # concatenate vectors after converting to character"
  },
  {
    "objectID": "reference.html#lesson-3-manipulating-analyzing-and-exporting-data-with-tidyverse",
    "href": "reference.html#lesson-3-manipulating-analyzing-and-exporting-data-with-tidyverse",
    "title": "Centre for Applied Bioinformatics R Workshop",
    "section": "Lesson 3 ‚Äì Manipulating, analyzing and exporting data with tidyverse",
    "text": "Lesson 3 ‚Äì Manipulating, analyzing and exporting data with tidyverse\n\nstr() # check structure of the object and information about the class, length and content of each column\nview() # invoke a spreadsheet-style data viewer\nselect() # select columns of a data frame\nfilter() # allows you to select a subset of rows in a data frame\n%>% # pipes to select and filter at the same time\nmutate() # create new columns based on the values in existing columns\nhead() # shows the first 6 rows\ngroup_by() # split the data into groups, apply some analysis to each group, and then combine the results.\nsummarize() # collapses each group into a single-row summary of that group\nmean() # calculate the mean value of a vector\n\n!is.na() # test if there are no missing values\nprint() # print values to the console\nmin() # return the minimum value of a vector\narrange() # arrange rows by variables\ndesc() # transform a vector into a format that will be sorted in descending order\ncount() # counts the total number of records for each category\nspread() # reshape a data frame by a key-value pair across multiple columns\ngather() # reshape a data frame by collapsing into a key-value pair\nn_distinct() # get a count of unique values\nwrite_csv() # save to a csv formatted file"
  },
  {
    "objectID": "reference.html#lesson-4-data-visualization-with-ggplot2",
    "href": "reference.html#lesson-4-data-visualization-with-ggplot2",
    "title": "Centre for Applied Bioinformatics R Workshop",
    "section": "Lesson 4 ‚Äì Data visualization with ggplot2",
    "text": "Lesson 4 ‚Äì Data visualization with ggplot2\n\nread_csv() # load a csv formatted file into R memory\nggplot2(data= , aes(x= , y= )) + geom_point( ) + facet_wrap () + theme_bw() + theme()\naes() # by selecting the variables to be plotted and the variables to define the presentation such as plotting size, shape color, etc.\ngeom_ # graphical representation of the data in the plot (points, lines, bars). To add a geom to the plot use + operator\nfacet_wrap() # allows to split one plot into multiple plots based on a factor included in the dataset\nlabs() # set labels to plot\ntheme_bw() # set the background to white\ntheme() # used to locally modify one or more theme elements in a specific ggplot object\n+ # arrange ggplots horizontally\n/ # arrange ggplots vertically\nplot_layout() # set width and height of individual plots in a patchwork of plots\nggsave() # save a ggplot"
  },
  {
    "objectID": "reference.html#lesson-5-sql-databases-and-r",
    "href": "reference.html#lesson-5-sql-databases-and-r",
    "title": "Centre for Applied Bioinformatics R Workshop",
    "section": "Lesson 5 ‚Äì SQL databases and R",
    "text": "Lesson 5 ‚Äì SQL databases and R\n\ndir.create() # create a directory\ndownload.file() # download files from the internet to your computer\ndbConnect() # create a connection to a database\nSQLite() # connect to a SQLite database\nsrc_dbi() # connect dplyr to a DBI-compatible database file\ntbl # connect to a table within a database\nsql() # combine character vectors into a single SQL expression\nshow_query() # show which SQL commands are sent to the database\ncollect() # retrieve all the results from the database\ninner_join() # perform an inner join between two tables\nsrc_sqlite() # connect dplyr to a SQLite database file\ncopy_to() # copy a data frame as a table into a database"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Required Software",
    "section": "",
    "text": "Data Carpentry‚Äôs aim is to teach researchers basic concepts, skills, and tools for working with data so that they can get more done in less time, and with less pain. The lessons below were designed for those interested in working with ecology data in R.\nThis is an introduction to R designed for participants with no programming experience. These lessons can be taught in a day (~ 6 hours). They start with some basic information about R syntax, the RStudio interface, and move through how to import CSV files, the structure of data frames, how to deal with factors, how to add/remove rows and columns, how to calculate summary statistics from a data frame, and a brief introduction to plotting. The last lesson demonstrates how to work with databases directly from R.\nThis lesson assumes no prior knowledge of R or RStudio and no programming experience."
  },
  {
    "objectID": "index.html#workshop",
    "href": "index.html#workshop",
    "title": "Required Software",
    "section": "Workshop",
    "text": "Workshop\n\nBefore we start\nIntroduction to R\nStarting with data\nManipulating, analyzing and exporting data with tidyverse\nData visualization with ggplot2"
  },
  {
    "objectID": "index.html#preparations",
    "href": "index.html#preparations",
    "title": "Required Software",
    "section": "Preparations",
    "text": "Preparations\nData Carpentry‚Äôs teaching is hands-on, and to follow this lesson learners must have R and RStudio installed on their computers. They also need to be able to install a number of R packages, create directories, and download files.\nTo avoid troubleshooting during the lesson, learners should follow the instruction below to download and install everything beforehand. If they are using their own computers this should be no problem, but if the computer is managed by their organization‚Äôs IT department they might need help from an IT administrator.\nInstall R and RStudio\nR and RStudio are two separate pieces of software:\n\n\nR is a programming language that is especially powerful for data exploration, visualization, and statistical analysis\n\nRStudio is an integrated development environment (IDE) that makes using R easier. In this course we use RStudio to interact with\n\n\n\n\n\nIf you don‚Äôt already have R and RStudio installed, follow the instructions for your operating system below. You have to install R before you install RStudio.\nWindows\n\nDownload R from the CRAN website.\nRun the .exe file that was just downloaded\nGo to the RStudio download page\n\nUnder Installers select RStudio x.yy.zzz - Windows Vista/7/8/10 (where x, y, and z represent version numbers)\nDouble click the file to install it\nOnce it‚Äôs installed, open RStudio to make sure it works and you don‚Äôt get any error messages.\n\n\n\n\n\n\n\nUWA Laptop Users\n\n\n\nIf you are using a UWA provided laptop, the ‚ÄòDocuments‚Äô folder (where R / RStudio normally stores files) will be a network-mapped drive. This will cause the installation and use of R packages to be VERY VERY SLOW.\nSolution:\nYou will need to create a folder for installing packages that will be kept only on your local machine, potentially just the desktop or another non-network folder.\nFor example:\nC:\\Users\\bradyjohnston\\Desktop\\R\\win-library\nor\nC:\\Users\\bradyjohnston\\R\\win-library\nThen create a file called .Renviron in your home directory, for me it would be:\nC:\\Users\\bradyjohnston\\\nInside of this file, include a single line that specifies the folder you created where you wish to install your packages:\nR_LIBS_USER=C:\\Users\\bradyjohnston\\Desktop\\R\\win-library\nThis should enable quick install of packages.\n\n\n\nMacOS\n\nDownload R from the CRAN website.\nSelect the .pkg file for the latest R version\nDouble click on the downloaded file to install R\nIt is also a good idea to install XQuartz (needed by some packages)\nGo to the RStudio download page\n\nUnder Installers select RStudio x.yy.zzz - Mac OS X 10.6+ (64-bit) (where x, y, and z represent version numbers)\nDouble click the file to install RStudio\nOnce it‚Äôs installed, open RStudio to make sure it works and you don‚Äôt get any error messages.\nLinux\n\nFollow the instructions for your distribution from CRAN, they provide information to get the most recent version of R for common distributions. For most distributions, you could use your package manager (e.g., for Debian/Ubuntu run sudo apt-get install r-base, and for Fedora sudo yum install R), but we don‚Äôt recommend this approach as the versions provided by this are usually out of date. In any case, make sure you have at least R 3.3.1.\nGo to the RStudio download page\n\nUnder Installers select the version that matches your distribution, and install it with your preferred method (e.g., with Debian/Ubuntu sudo dpkg -i   rstudio-x.yy.zzz-amd64.deb at the terminal).\nOnce it‚Äôs installed, open RStudio to make sure it works and you don‚Äôt get any error messages.\nUpdate R and RStudio\nIf you already have R and RStudio installed, first check if your R version is up to date:\n\nWhen you open RStudio your R version will be printed in the console on the bottom left. Alternatively, you can type sessionInfo() into the console. If your R version is 4.0.0 or later, you don‚Äôt need to update R for this lesson. If your version of R is older than that, download and install the latest version of R from the R project website for Windows, for MacOS, or for Linux\n\nIt is not necessary to remove old versions of R from your system, but if you wish to do so you can check How do I uninstall R?\n\nNote: The changes introduced by new R versions are usually backwards-compatible. That is, your old code should still work after updating your R version. However, if breaking changes happen, it is useful to know that you can have multiple versions of R installed in parallel and that you can switch between them in RStudio by going to Tools > Global Options > General > Basic.\nAfter installing a new version of R, you will have to reinstall all your packages with the new version. For Windows, there is a package called installr that can help you with upgrading your R version and migrate your package library.\n\nTo update RStudio to the latest version, open RStudio and click on Help > Check for Updates. If a new version is available follow the instruction on screen. By default, RStudio will also automatically notify you of new versions every once in a while.\nInstall required R packages\nDuring the course we will need a number of R packages. Packages contain useful R code written by other people. We will use the packages tidyverse, hexbin, patchwork, and RSQLite.\nTo try to install these packages, open RStudio and copy and paste the following command into the console window (look for a blinking cursor on the bottom left), then press the Enter (Windows and Linux) or Return (MacOS) to execute the command.\n\ninstall.packages(c(\"tidyverse\", \"hexbin\", \"patchwork\", \"RSQLite\"))\n\nAlternatively, you can install the packages using RStudio‚Äôs graphical user interface by going to Tools > Install Packages and typing the names of the packages separated by a comma.\nR tries to download and install the packages on your machine. When the installation has finished, you can try to load the packages by pasting the following code into the console:\n\nlibrary(tidyverse)\nlibrary(hexbin)\nlibrary(patchwork)\nlibrary(RSQLite)\n\nIf you do not see an error like there is no package called ‚Äò...‚Äô you are good to go!\nUpdating R packages\nGenerally, it is recommended to keep your R version and all packages up to date, because new versions bring improvements and important bugfixes. To update the packages that you have installed, click Update in the Packages tab in the bottom right panel of RStudio, or go to Tools > Check for Package Updates....\nSometimes, package updates introduce changes that break your old code, which can be very frustrating. To avoid this problem, you can use a package called renv. It locks the package versions you have used for a given project and makes it straightforward to reinstall those exact package version in a new environment, for example after updating your R version or on another computer. However, the details are outside of the scope of this lesson.\nDownload the data\nWe will download the data directly from R during the lessons. However, if you are expecting problems with the network, it may be better to download the data beforehand and store it on your machine.\nThe data files for the lesson can be downloaded manually here: https://doi.org/10.6084/m9.figshare.1314459"
  },
  {
    "objectID": "index.html#contributors",
    "href": "index.html#contributors",
    "title": "Required Software",
    "section": "Contributors",
    "text": "Contributors\nThe list of contributors to this lesson is available here.\n\nPage built on: üìÜ 2022-06-29 ‚Äí üï¢ 15:33:26"
  },
  {
    "objectID": "NEWS.html",
    "href": "NEWS.html",
    "title": "Centre for Applied Bioinformatics R Workshop",
    "section": "",
    "text": "Initial release of the Data Carpentry R ecology lesson."
  },
  {
    "objectID": "before-we-start.html#what-is-r-what-is-rstudio",
    "href": "before-we-start.html#what-is-r-what-is-rstudio",
    "title": "Before we start",
    "section": "What is R? What is RStudio?",
    "text": "What is R? What is RStudio?\nThe term ‚ÄúR‚Äù is used to refer to both the programming language and the software that interprets the scripts written using it.\nRStudio is currently a very popular way to not only write your R scripts but also to interact with the R software. To function correctly, RStudio needs R and therefore both need to be installed on your computer."
  },
  {
    "objectID": "before-we-start.html#why-learn-r",
    "href": "before-we-start.html#why-learn-r",
    "title": "Before we start",
    "section": "Why learn R?",
    "text": "Why learn R?\nR does not involve lots of pointing and clicking, and that‚Äôs a good thing\nThe learning curve might be steeper than with other software, but with R, the results of your analysis do not rely on remembering a succession of pointing and clicking, but instead on a series of written commands, and that‚Äôs a good thing! So, if you want to redo your analysis because you collected more data, you don‚Äôt have to remember which button you clicked in which order to obtain your results. With a stored series of commands (this is your script), you can repeat running them and R will process the new dataset exactly the same way as before.\nWorking with scripts makes the steps you used in your analysis clear, and the code you write can be inspected by someone else who can give you feedback and spot mistakes.\nWorking with scripts forces you to have a deeper understanding of what you are doing, and facilitates your learning and comprehension of the methods you use.\nR code is great for reproducibility\nReproducibility is when someone else (including your future self) can obtain the same results from the same dataset when using the same analysis.\nR integrates with other tools to generate manuscripts from your code. If you collect more data, or fix a mistake in your dataset, the figures and the statistical tests in your manuscript are updated automatically.\nAn increasing number of journals and funding agencies expect analyses to be reproducible, so knowing R will give you an edge with these requirements.\nR is interdisciplinary and extensible\nWith 10,000+ packages that can be installed to extend its capabilities, R provides a framework that allows you to combine statistical approaches from many scientific disciplines to best suit the analytical framework you need to analyze your data. For instance, R has packages for image analysis, GIS, time series, population genetics, and a lot more.\nR works on data of all shapes and sizes\nThe skills you learn with R scale easily with the size of your dataset. Whether your dataset has hundreds or millions of lines, it won‚Äôt make much difference to you.\nR is designed for data analysis. It comes with special data structures and data types that make handling of missing data and statistical factors convenient.\nR can connect to spreadsheets, databases, and many other data formats, on your computer or on the web.\nR produces high-quality graphics\nThe plotting functionalities in R are endless, and allow you to adjust any aspect of your graph to convey most effectively the message from your data.\nR has a large and welcoming community\nThousands of people use R daily. Many of them are willing to help you through mailing lists and websites such as Stack Overflow, or on the RStudio community.\nNot only is R free, but it is also open-source and cross-platform\nAnyone can inspect the source code to see how R works. Because of this transparency, there is less chance for mistakes, and if you (or someone else) find some, you can report and fix bugs."
  },
  {
    "objectID": "before-we-start.html#knowing-your-way-around-rstudio",
    "href": "before-we-start.html#knowing-your-way-around-rstudio",
    "title": "Before we start",
    "section": "Knowing your way around RStudio",
    "text": "Knowing your way around RStudio\nLet‚Äôs start by learning about RStudio, which is an Integrated Development Environment (IDE) for working with R.\nThe RStudio IDE open-source product is free under the Affero General Public License (AGPL) v3. The RStudio IDE is also available with a commercial license and priority email support from RStudio, PBC.\nWe will use RStudio IDE to write code, navigate the files on our computer, inspect the variables we are going to create, and visualize the plots we will generate. RStudio can also be used for other things (e.g., version control, developing packages, writing Shiny apps) that we will not cover during the workshop.\n\n\nRStudio interface screenshot. Clockwise from top left: Source, Environment/History, Files/Plots/Packages/Help/Viewer, Console.\n\n\nRStudio is divided into 4 ‚Äúpanes‚Äù:\n\nThe Source for your scripts and documents (top-left, in the default layout)\nYour Environment/History (top-right) which shows all the objects in your working space (Environment) and your command history (History)\nYour Files/Plots/Packages/Help/Viewer (bottom-right)\nThe R Console (bottom-left)\n\nThe placement of these panes and their content can be customized (see menu, Tools -> Global Options -> Pane Layout). For ease of use, settings such as background color, font color, font size, and zoom level can also be adjusted in this menu (Global Options -> Appearance).\nOne of the advantages of using RStudio is that all the information you need to write code is available in a single window. Additionally, with many shortcuts, autocompletion, and highlighting for the major file types you use while developing in R, RStudio will make typing easier and less error-prone."
  },
  {
    "objectID": "before-we-start.html#getting-set-up",
    "href": "before-we-start.html#getting-set-up",
    "title": "Before we start",
    "section": "Getting set up",
    "text": "Getting set up\nIt is good practice to keep a set of related data, analyses, and text self-contained in a single folder, called the working directory. All of the scripts within this folder can then use relative paths to files that indicate where inside the project a file is located (as opposed to absolute paths, which point to where a file is on a specific computer). Working this way allows you to move your project around on your computer and share it with others without worrying about whether or not the underlying scripts will still work.\nRStudio provides a helpful set of tools to do this through its ‚ÄúProjects‚Äù interface, which not only creates a working directory for you, but also remembers its location (allowing you to quickly navigate to it) and optionally preserves custom settings and (re-)open files to assist resume work after a break. Go through the steps for creating an ‚ÄúR Project‚Äù for this tutorial below.\n\nStart RStudio.\nUnder the File menu, click on New Project. Choose New Directory, then New Project.\nEnter a name for this new folder (or ‚Äúdirectory‚Äù), and choose a convenient location for it. This will be your working directory for the rest of the day (e.g., ~/data-carpentry).\nClick on Create Project.\nDownload the code handout, place it in your working directory and rename it (e.g., data-carpentry-script.R).\n(Optional) Set Preferences to ‚ÄòNever‚Äô save workspace in RStudio.\n\nA workspace is your current working environment in R which includes any user-defined object. By default, all of these objects will be saved, and automatically loaded, when you reopen your project. Saving a workspace to .RData can be cumbersome, especially if you are working with larger datasets, and it can lead to hard to debug errors by having objects in memory you forgot you had. Therefore, it is often a good idea to turn this off. To do so, go to Tools ‚Äì> ‚ÄòGlobal Options‚Äô and select the ‚ÄòNever‚Äô option for ‚ÄòSave workspace to .RData‚Äô on exit.‚Äô\n\n\nSet ‚ÄòSave workspace to .RData on exit‚Äô to ‚ÄòNever‚Äô\n\n\nOrganizing your working directory\nUsing a consistent folder structure across your projects will help keep things organized, and will help you to find/file things in the future. This can be especially helpful when you have multiple projects. In general, you may create directories (folders) for scripts, data, and documents.\n\n\ndata_raw/ & data/ Use these folders to store raw data and intermediate datasets you may create for the need of a particular analysis. For the sake of transparency and provenance, you should always keep a copy of your raw data accessible and do as much of your data cleanup and preprocessing programmatically (i.e., with scripts, rather than manually) as possible. Separating raw data from processed data is also a good idea. For example, you could have files data_raw/tree_survey.plot1.txt and ...plot2.txt kept separate from a data/tree.survey.csv file generated by the scripts/01.preprocess.tree_survey.R script.\n\ndocuments/ This would be a place to keep outlines, drafts, and other text.\n\nscripts/ This would be the location to keep your R scripts for different analyses or plotting, and potentially a separate folder for your functions (more on that later).\n\nAdditional (sub)directories depending on your project needs.\n\nFor this workshop, we will need a data_raw/ folder to store our raw data, and we will use data/ for when we learn how to export data as CSV files, and a fig/ folder for the figures that we will save.\n\nUnder the Files tab on the right of the screen, click on New Folder and create a folder named data_raw within your newly created working directory (e.g., ~/data-carpentry/). (Alternatively, type dir.create(\"data_raw\") at your R console.) Repeat these operations to create a data and a fig folder.\n\nWe are going to keep the script in the root of our working directory because we are only going to use one file. Later, when you start create more complex projects, it might make sense to organize scripts in sub-directories.\nYour working directory should now look like this:\n\n\n\n\nHow it should look like at the beginning of this lesson\n\n\n\n\nThe working directory\nThe working directory is an important concept to understand. It is the place from where R will be looking for and saving the files. When you write code for your project, it should refer to files in relation to the root of your working directory and only need files within this structure.\nRStudio assists you in this regard and sets the working directory automatically to the directory where you have placed your project in. If you need to check it, you can use getwd(). If for some reason your working directory is not what it should be, you can change it in the RStudio interface by navigating in the file browser where your working directory should be, and clicking on the blue gear icon ‚ÄúMore‚Äù, and select ‚ÄúSet As Working Directory‚Äù. Alternatively you can use setwd(\"/path/to/working/directory\") to reset your working directory. However, your scripts should not include this line because it will fail on someone else‚Äôs computer."
  },
  {
    "objectID": "before-we-start.html#interacting-with-r",
    "href": "before-we-start.html#interacting-with-r",
    "title": "Before we start",
    "section": "Interacting with R",
    "text": "Interacting with R\nThe basis of programming is that we write down instructions for the computer to follow, and then we tell the computer to follow those instructions. We write, or code, instructions in R because it is a common language that both the computer and we can understand. We call the instructions commands and we tell the computer to follow the instructions by executing (also called running) those commands.\nThere are two main ways of interacting with R: by using the console or by using script files (plain text files that contain your code). The console pane (in RStudio, the bottom left panel) is the place where commands written in the R language can be typed and executed immediately by the computer. It is also where the results will be shown for commands that have been executed. You can type commands directly into the console and press Enter to execute those commands, but they will be forgotten when you close the session.\nBecause we want our code and workflow to be reproducible, it is better to type the commands we want in the script editor, and save the script. This way, there is a complete record of what we did, and anyone (including our future selves!) can easily replicate the results on their computer.\nRStudio allows you to execute commands directly from the script editor by using the Ctrl + Enter shortcut (on Macs, Cmd + Return will work, too). The command on the current line in the script (indicated by the cursor) or all of the commands in the currently selected text will be sent to the console and executed when you press Ctrl + Enter. You can find other keyboard shortcuts in this RStudio cheatsheet about the RStudio IDE.\nAt some point in your analysis you may want to check the content of a variable or the structure of an object, without necessarily keeping a record of it in your script. You can type these commands and execute them directly in the console. RStudio provides the Ctrl + 1 and Ctrl + 2 shortcuts allow you to jump between the script and the console panes.\nIf R is ready to accept commands, the R console shows a > prompt. If it receives a command (by typing, copy-pasting or sent from the script editor using Ctrl + Enter), R will try to execute it, and when ready, will show the results and come back with a new > prompt to wait for new commands.\nIf R is still waiting for you to enter more data because it isn‚Äôt complete yet, the console will show a + prompt. It means that you haven‚Äôt finished entering a complete command. This is because you have not ‚Äòclosed‚Äô a parenthesis or quotation, i.e.¬†you don‚Äôt have the same number of left-parentheses as right-parentheses, or the same number of opening and closing quotation marks. When this happens, and you thought you finished typing your command, click inside the console window and press Esc; this will cancel the incomplete command and return you to the > prompt."
  },
  {
    "objectID": "before-we-start.html#seeking-help",
    "href": "before-we-start.html#seeking-help",
    "title": "Before we start",
    "section": "Seeking help",
    "text": "Seeking help\nSearching function documentation with ? and ??\n\nIf you need help with a specific function, let‚Äôs say mean(), you can type ?mean or press F1 while your cursor is on the function name. If you are looking for a function to do a particular task, but don‚Äôt know the function name, you can use the double question mark ??, for example ??kruskall. Both commands will open matching help files in RStudio‚Äôs help panel in the lower right corner. You can also use the help panel to search help directly, as seen in the screenshot.\n\n\nRStudio help panel. When typing a word in the search field, it will show related suggestions.\n\n\nAutomatic code completion\nWhen you write code in RStudio, you can use its automatic code completion to remind yourself of a function‚Äôs name or arguments. Start typing the function name and pay attention to the suggestions that pop up. Use the up and down arrow to select a suggested code completion and Tab to apply it. You can also use code completion to complete function‚Äôs argument names, object, names and file names. It even works if you don‚Äôt get the spelling 100% correct.\nPackage vignettes and cheat sheets\nIn addition to the documentation for individual functions, many packages have vignettes ‚Äì instructions for how to use the package to do certain tasks. Vignettes are great for learning by example. Vignettes are accessible via the package help and by using the function browseVignettes().\nThere is also a Help menu at the top of the RStudio window, that has cheat sheets for popular packages, RStudio keyboard shortcuts, and more.\nFinding more functions and packages\nRStudio‚Äôs help only searches the packages that you have installed on your machine, but there are many more available on CRAN and GitHub. To search across all available R packages, you can use the website rdocumentation.org. Often, a generic Google or internet search ‚ÄúR <task>‚Äù will send you to the appropriate package documentation or a forum where someone else has already asked your question. Many packages also have websites with additional help, tutorials, news and more (for example tidyverse.org).\nDealing with error messages\nDon‚Äôt get discouraged if your code doesn‚Äôt run immediately! Error messages are common when programming, and fixing errors is part of any programmer‚Äôs daily work. Often, the problem is a small typo in a variable name or a missing parenthesis. Watch for the red x‚Äôs next to your code in RStudio. These may provide helpful hints about the source of the problem.\n\n\nRStudio shows a red x next to a line of code that R doesn‚Äôt understand.\n\n\nIf you can‚Äôt fix an error yourself, start by googling it. Some error messages are too generic to diagnose a problem (e.g.¬†‚Äúsubscript out of bounds‚Äù). In that case it might help to include the name of the function or package you‚Äôre using in your query.\nAsking for help\nIf your Google search is unsuccessful, you may want to ask other R users for help. There are different places where you can ask for help. During this workshop, don‚Äôt hesitate to talk to your neighbor, compare your answers, and ask for help. You might also be interested in organizing regular meetings following the workshop to keep learning from each other. If you have a friend or colleague with more experience than you, they might also be able and willing to help you.\nBesides that, there are a few places on the internet that provide help:\n\n\nStack Overflow: Many questions have already been answered, but the challenge is to use the right words in your search to find them. If your question hasn‚Äôt been answered before and is well crafted, chances are you will get an answer in less than 5 min. Remember to follow their guidelines on how to ask a good question.\nThe R-help mailing list: it is used by a lot of people (including most of the R core team). If your question is valid (read its Posting Guide), you are likely to get an answer very fast, but the tone can be pretty dry and it is not always very welcoming to new users.\nIf your question is about a specific package rather than a base R function, see if there is a mailing list for the package. Usually it‚Äôs included in the DESCRIPTION file of the package that can be accessed using packageDescription(\"<package-name>\").\nYou can also try to contact the package author directly, by emailing them or opening an issue on the code repository (e.g., on GitHub).\nThere are also some topic-specific mailing lists (GIS, phylogenetics, etc‚Ä¶). The complete list is on the R mailing lists website.\n\nThe key to receiving help from someone is for them to rapidly grasp your problem. Thus, you should be as precise as possible when describing your problem and help others to pinpoint where the issue might be. Try to‚Ä¶\n\nUse the correct words to describe your problem. Otherwise you might get an answer pointing to the misuse of your words rather than answering your question.\nGeneralize what you are trying to do, so people outside your field can understand the question.\nReduce what does not work to a simple reproducible example. For instance, instead of using your real data set, create a small generic one. For more information on how to write a reproducible example see this article from the reprex package. Learning how to use the reprex package is also very helpful for this.\nInclude the output of sessionInfo() in your question. It provides information about your platform, the versions of R and the packages that you are using. As an example, here you can see the versions of R and all the packages that we are using to run the code in this lesson:\n\n\n\n\n\nsessionInfo()\n\n#> R version 4.2.0 (2022-04-22)\n#> Platform: x86_64-apple-darwin17.0 (64-bit)\n#> Running under: macOS Big Sur/Monterey 10.16\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n#> \n#> locale:\n#> [1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] RSQLite_2.2.14  forcats_0.5.1   stringr_1.4.0   dplyr_1.0.9    \n#>  [5] purrr_0.3.4     readr_2.1.2     tidyr_1.2.0     tibble_3.1.7   \n#>  [9] ggplot2_3.3.6   tidyverse_1.3.1 knitr_1.39     \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] tidyselect_1.1.2 xfun_0.31        haven_2.5.0      colorspace_2.0-3\n#>  [5] vctrs_0.4.1      generics_0.1.2   htmltools_0.5.2  yaml_2.3.5      \n#>  [9] blob_1.2.3       utf8_1.2.2       rlang_1.0.2      pillar_1.7.0    \n#> [13] glue_1.6.2       withr_2.5.0      DBI_1.1.3        bit64_4.0.5     \n#> [17] dbplyr_2.2.1     modelr_0.1.8     readxl_1.4.0     lifecycle_1.0.1 \n#> [21] munsell_0.5.0    gtable_0.3.0     cellranger_1.1.0 rvest_1.0.2     \n#> [25] memoise_2.0.1    evaluate_0.15    tzdb_0.3.0       fastmap_1.1.0   \n#> [29] fansi_1.0.3      Rcpp_1.0.8.3     broom_0.8.0      backports_1.4.1 \n#> [33] scales_1.2.0     cachem_1.0.6     jsonlite_1.8.0   bit_4.0.4       \n#> [37] fs_1.5.2         hms_1.1.1        digest_0.6.29    stringi_1.7.6   \n#> [41] grid_4.2.0       cli_3.3.0        tools_4.2.0      magrittr_2.0.3  \n#> [45] crayon_1.5.1     pkgconfig_2.0.3  ellipsis_0.3.2   xml2_1.3.3      \n#> [49] reprex_2.0.1     lubridate_1.8.0  rstudioapi_0.13  assertthat_0.2.1\n#> [53] rmarkdown_2.14   httr_1.4.3       R6_2.5.1         compiler_4.2.0"
  },
  {
    "objectID": "before-we-start.html#how-to-learn-more-after-the-workshop",
    "href": "before-we-start.html#how-to-learn-more-after-the-workshop",
    "title": "Before we start",
    "section": "How to learn more after the workshop?",
    "text": "How to learn more after the workshop?\nThe material we cover during this workshop will give you a taste of how you can use R to analyze data for your own research. However, to do advanced operations such as cleaning your dataset, using statistical methods, or creating beautiful graphics you will need to learn more.\nThe best way to become proficient and efficient at R, as with any other tool, is to use it to address your actual research questions. As a beginner, it can feel daunting to have to write a script from scratch, and given that many people make their code available online, modifying existing code to suit your purpose might get first hands-on experience using R for your own work and help you become comfortable eventually creating your own scripts."
  },
  {
    "objectID": "before-we-start.html#more-resources",
    "href": "before-we-start.html#more-resources",
    "title": "Before we start",
    "section": "More resources",
    "text": "More resources\nMore about R\n\nThe Introduction to R can also be dense for people with little programming experience but it is a good place to understand the underpinnings of the R language.\nThe R FAQ is dense and technical but it is full of useful information.\nTo stay up to date, follow #rstats on twitter. Twitter can also be a way to get questions answered and learn about useful R packages and tipps (e.g., [@RLangTips])\nHow to ask good programming questions?\n\nThe rOpenSci community call ‚ÄúHow to ask questions so they get answered‚Äù, (rOpenSci site and video recording) includes a presentation of the reprex package and of its philosophy.\n\nblog.Revolutionanalytics.com and this blog post by Jon Skeet have comprehensive advice on how to ask programming questions.\n\n\nPage built on: üìÜ 2022-06-28 ‚Äí üï¢ 17:22:26"
  },
  {
    "objectID": "CITATION.html",
    "href": "CITATION.html",
    "title": "Centre for Applied Bioinformatics R Workshop",
    "section": "",
    "text": "Warning in system(\"update-copyright.py\"): error in running command\n\n\n\nData is from the paper S. K. Morgan Ernest, Thomas J. Valone, and James H. Brown. 2009. Long-term monitoring and experimental manipulation of a Chihuahuan Desert ecosystem near Portal, Arizona, USA. Ecology 90:1708.\nhttp://esapubs.org/archive/ecol/E090/118/\nA simplified version of this data, suitable for teaching is available on figshare.\n\nThe first workshop was run at NESCent on May 8-9, 2014 with the development and instruction of lessons by Karen Cranston, Hilmar Lapp, Tracy Teal, and Ethan White and contributions from Deb Paul and Mike Smorul.\nOriginal materials adapted from SWC Python lessons by Sarah Supp. John Blischak led the continued development of materials with contributions from Gavin Simpson, Tracy Teal, Greg Wilson, Diego Barneche, Stephen Turner, and Karthik Ram. This original material has been modified and expanded by Fran√ßois Michonneau.\nThe dplyr lesson was created by Kara Woo, who copied and modified and modified from Jeff Hollister‚Äôs materials.\nThe ggplot2 lesson was initially created by Mateusz Kuzak, Diana Marek, and Hedi Peterson, during a Hackathon in Espoo, Finland on March 16-17, 2015, sponsored by the ELIXIR project.\nYou can cite this Data Carpentry lesson as follow:\n\nMichonneau F, Teal T, Fournier A, Seok B, Obeng A, Pawlik AN, Conrado AC, Woo K, Lijnzaad P, Hart T, White EP, Marwick B, Bolker B, Jordan KL, Ashander J, Dashnow H, Hertweck K, Cuesta SM, Becker EA, Guillou S, Shiklomanov A, Klinges D, Odom GJ, Jean M, Mislan KAS, Johnson K, Jahn N, Mannheimer S, Pederson S, Pletzer A, Fouilloux A, Switzer C, Bahlai C, Li D, Kerchner D, Rodriguez-Sanchez F, Rajeg GPW, Ye H, Tavares H, Leinweber K, Peck K, Lepore ML, Hancock S, Sandmann T, Hodges T, Tirok K, Jean M, Bailey A, von Hardenberg A, Theobold A, Wright A, Basu A, Johnson C, Voter C, Hulshof C, Bouquin D, Quinn D, Vanichkina D, Wilson E, Strauss E, Bledsoe E, Gan E, Fishman D, Boehm F, Daskalova G, Tavares H, Kaupp J, Dunic J, Keane J, Stachelek J, Herr JR, Millar J, Lotterhos K, Cranston K, Direk K, Tyl√©n K, Chatzidimitriou K, Deer L, Tarkowski L, Chiapello M, Burle M, Ankenbrand M, Czapanskiy M, Moreno M, Culshaw-Maurer M, Koontz M, Weisner M, Johnston M, Carchedi N, Burge OR, Harrison P, Humburg P, Pauloo R, Peek R, Elahi R, Cortijo S, sfn_brt, Umashankar S, Goswami S, Sumedh, Yanco S, Webster T, Reiter T, Pearse W, Li Y (2022). ‚Äúdatacarpentry/R-ecology-lesson: Data Carpentry: Data Analysis and Visualization in R for Ecologists, June 2019.‚Äù doi:10.5281/zenodo.3264888, https://datacarpentry.org/R-ecology-lesson/.\n\nor as a BibTeX entry:\n\n\n@Misc{,\n  author = {Fran√ßois Michonneau and Tracy Teal and Auriel Fournier and Brian Seok and Adam Obeng and Aleksandra Natalia Pawlik and Ana Costa Conrado and Kara Woo and Philip Lijnzaad and Ted Hart and Ethan P White and Ben Marwick and Ben Bolker and Kari L Jordan and Jaime Ashander and Harriet Dashnow and Kate Hertweck and Sergio Mart√≠nez Cuesta and Erin Alison Becker and St√©phane Guillou and Alexey Shiklomanov and David Klinges and Gabriel J. Odom and Martin Jean and K. A. S. Mislan and Kayla Johnson and Najko Jahn and Sara Mannheimer and Steve Pederson and Alex Pletzer and Anne Fouilloux and Callin Switzer and Christie Bahlai and Daijiang Li and Dan Kerchner and Francisco Rodriguez-Sanchez and Gede Primahadi Wijaya Rajeg and Hao Ye and Hugo Tavares and Katrin Leinweber and Kayla Peck and Mauro Luciano Lepore and Stacey Hancock and Thomas Sandmann and Toby Hodges and Katrin Tirok and Martin Jean and Alistair Bailey and Achaz {von Hardenberg} and Allison Theobold and April Wright and Arindam Basu and Carolina Johnson and Carolyn Voter and Catherine Hulshof and Daina Bouquin and Danielle Quinn and Darya Vanichkina and Earle Wilson and Eli Strauss and Ellen Bledsoe and Emilia Gan and Dmytro Fishman and Fred Boehm and Gergana Daskalova and Hugo Tavares and Jake Kaupp and Jillian Dunic and Jonathan Keane and Joseph Stachelek and Joshua R. Herr and Justin Millar and Katie Lotterhos and Karen Cranston and Kenan Direk and Kristian Tyl√©n and Kyriakos Chatzidimitriou and Lachlan Deer and Leszek Tarkowski and Marco Chiapello and Marie-Helene Burle and Markus Ankenbrand and Max Czapanskiy and Melissa Moreno and Michael Culshaw-Maurer and Michael Koontz and Michael Weisner and Myfanwy Johnston and Nick Carchedi and Olivia Rata Burge and Paul Harrison and Peter Humburg and Richard Pauloo and Ryan Peek and Robin Elahi and Sandra Cortijo and {sfn_brt} and Shivshankar Umashankar and Shubhang Goswami and {Sumedh} and Scott Yanco and Tara Webster and Taylor Reiter and Will Pearse and Ye Li},\n  title = {datacarpentry/R-ecology-lesson: Data Carpentry: Data Analysis and Visualization in R for Ecologists, June 2019},\n  editor = {Ana Costa Conrado and Auriel M.V. Fournier and Brian Seok and Francois Michonneau},\n  month = {June},\n  year = {2022},\n  url = {https://datacarpentry.org/R-ecology-lesson/},\n  doi = {10.5281/zenodo.3264888},\n}\n\n\n\nPage built on: üìÜ 2022-06-28 ‚Äí üï¢ 17:22:28"
  },
  {
    "objectID": "02-starting-with-data.html#loading-the-survey-data",
    "href": "02-starting-with-data.html#loading-the-survey-data",
    "title": "Starting with data",
    "section": "Loading the survey data",
    "text": "Loading the survey data\n\n\n\nWe are investigating the animal species diversity and weights found within plots at our study site. The dataset is stored as a comma separated value (CSV) file. Each row holds information for a single animal, and the columns represent:\n\n\nColumn\nDescription\n\n\n\nrecord_id\nUnique id for the observation\n\n\nmonth\nmonth of observation\n\n\nday\nday of observation\n\n\nyear\nyear of observation\n\n\nplot_id\nID of a particular experimental plot of land\n\n\nspecies_id\n2-letter code\n\n\nsex\nsex of animal (‚ÄúM‚Äù, ‚ÄúF‚Äù)\n\n\nhindfoot_length\nlength of the hindfoot in mm\n\n\nweight\nweight of the animal in grams\n\n\ngenus\ngenus of animal\n\n\nspecies\nspecies of animal\n\n\ntaxon\ne.g.¬†Rodent, Reptile, Bird, Rabbit\n\n\nplot_type\ntype of plot\n\n\n\nDownloading the data\nWe created the folder that will store the downloaded data (data_raw) in the chapter ‚ÄúBefore we start‚Äù. If you skipped that part, it may be a good idea to have a look now, to make sure your working directory is set up properly.\nWe are going to use the R function download.file() to download the CSV file that contains the survey data from Figshare, and we will use read_csv() to load the content of the CSV file into R.\nInside the download.file command, the first entry is a character string with the source URL (‚Äúhttps://ndownloader.figshare.com/files/2292169‚Äù). This source URL downloads a CSV file from figshare. The text after the comma (‚Äúdata_raw/portal_data_joined.csv‚Äù) is the destination of the file on your local machine. You‚Äôll need to have a folder on your machine called ‚Äúdata_raw‚Äù where you‚Äôll download the file. So this command downloads a file from Figshare, names it ‚Äúportal_data_joined.csv‚Äù and adds it to a preexisting folder named ‚Äúdata_raw‚Äù.\n\ndownload.file(url = \"https://ndownloader.figshare.com/files/2292169\",\n              destfile = \"data_raw/portal_data_joined.csv\")\n\nReading the data into R\nThe file has now been downloaded to the destination you specified, but R has not yet loaded the data from the file into memory. To do this, we can use the read_csv() function from the tidyverse package.\nPackages in R are basically sets of additional functions that let you do more stuff. The functions we‚Äôve been using so far, like round(), sqrt(), or c() come built into R. Packages give you access to additional functions beyond base R. A similar function to read_csv() from the tidyverse package is read.csv() from base R. We don‚Äôt have time to cover their differences but notice that the exact spelling determines which function is used. Before you use a package for the first time you need to install it on your machine, and then you should import it in every subsequent R session when you need it.\nTo install the tidyverse package, we can type install.packages(\"tidyverse\") straight into the console. In fact, it‚Äôs better to write this in the console than in our script for any package, as there‚Äôs no need to re-install packages every time we run the script. Then, to load the package type:\n\n## load the tidyverse packages, incl. dplyr\nlibrary(tidyverse)\n\nNow we can use the functions from the tidyverse package. Let‚Äôs use read_csv() to read the data into a data frame (we will learn more about data frames later):\n\nsurveys <- read_csv(\"data_raw/portal_data_joined.csv\")\n\n#> Rows: 34786 Columns: 13\n#> ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#> Delimiter: \",\"\n#> chr (6): species_id, sex, genus, species, taxa, plot_type\n#> dbl (7): record_id, month, day, year, plot_id, hindfoot_length, weight\n#> \n#> ‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n#> ‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you execute read_csv on a data file, it looks through the first 1000 rows of each column and guesses its data type. For example, in this dataset, read_csv() reads weight as col_double (a numeric data type), and species as col_character. You have the option to specify the data type for a column manually by using the col_types argument in read_csv.\n\nNote\nread_csv() assumes that fields are delineated by commas. However, in several countries, the comma is used as a decimal separator and the semicolon (;) is used as a field delineator. If you want to read in this type of files in R, you can use the read_csv2() function. It behaves like read_csv() but uses different parameters for the decimal and the field separators. There is also the read_tsv() for tab separated data files and read_delim() for less common formats. Check out the help for read_csv() by typing ?read_csv to learn more.\nIn addition to the above versions of the csv format, you should develop the habits of looking at and recording some parameters of your csv files. For instance, the character encoding, control characters used for line ending, date format (if the date is not split into three variables), and the presence of unexpected newlines are important characteristics of your data files. Those parameters will ease up the import step of your data in R.\n\nWe can see the contents of the first few lines of the data by typing its name: surveys. By default, this will show you as many rows and columns of the data as fit on your screen. If you wanted the first 50 rows, you could type print(surveys, n = 50)\nWe can also extract the first few lines of this data using the function head():\n\nhead(surveys)\n\n#> # A tibble: 6 √ó 13\n#>   record_id month   day  year plot_id species_id sex   hindfoot_length weight\n#>       <dbl> <dbl> <dbl> <dbl>   <dbl> <chr>      <chr>           <dbl>  <dbl>\n#> 1         1     7    16  1977       2 NL         M                  32     NA\n#> 2        72     8    19  1977       2 NL         M                  31     NA\n#> 3       224     9    13  1977       2 NL         <NA>               NA     NA\n#> 4       266    10    16  1977       2 NL         <NA>               NA     NA\n#> 5       349    11    12  1977       2 NL         <NA>               NA     NA\n#> 6       363    11    12  1977       2 NL         <NA>               NA     NA\n#> # ‚Ä¶ with 4 more variables: genus <chr>, species <chr>, taxa <chr>,\n#> #   plot_type <chr>\n\n\nUnlike the print() function, head() returns the extracted data. You could use it to assign the first 100 rows of surveys to an object using surveys_sample <- head(surveys, 100). This can be useful if you want to try out complex computations on a subset of your data before you apply them to the whole data set. There is a similar function that lets you extract the last few lines of the data set. It is called (you might have guessed it) tail().\nTo open the dataset in RStudio‚Äôs Data Viewer, use the view() function:\n\nview(surveys)\n\n\nNote\nThere are two functions for viewing which are case-sensitive. Using view() with a lowercase ‚Äòv‚Äô is part of tidyverse, whereas using View() with an uppercase ‚ÄòV‚Äô is loaded through base R in the utils package."
  },
  {
    "objectID": "02-starting-with-data.html#what-are-data-frames",
    "href": "02-starting-with-data.html#what-are-data-frames",
    "title": "Starting with data",
    "section": "What are data frames?",
    "text": "What are data frames?\nWhen we loaded the data into R, it got stored as an object of class tibble, which is a special kind of data frame (the difference is not important for our purposes, but you can learn more about tibbles here). Data frames are the de facto data structure for most tabular data, and what we use for statistics and plotting. Data frames can be created by hand, but most commonly they are generated by functions like read_csv(); in other words, when importing spreadsheets from your hard drive or the web.\nA data frame is the representation of data in the format of a table where the columns are vectors that all have the same length. Because columns are vectors, each column must contain a single type of data (e.g., characters, integers, factors). For example, here is a figure depicting a data frame comprising a numeric, a character, and a logical vector.\n\nWe can see this also when inspecting the structure of a data frame with the function str():\n\nstr(surveys)"
  },
  {
    "objectID": "02-starting-with-data.html#inspecting-data-frames",
    "href": "02-starting-with-data.html#inspecting-data-frames",
    "title": "Starting with data",
    "section": "Inspecting data frames",
    "text": "Inspecting data frames\nWe already saw how the functions head() and str() can be useful to check the content and the structure of a data frame. Here is a non-exhaustive list of functions to get a sense of the content/structure of the data. Let‚Äôs try them out!\n\nSize:\n\n\ndim(surveys) - returns a vector with the number of rows in the first element, and the number of columns as the second element (the dimensions of the object)\n\nnrow(surveys) - returns the number of rows\n\nncol(surveys) - returns the number of columns\n\n\nContent:\n\n\nhead(surveys) - shows the first 6 rows\n\ntail(surveys) - shows the last 6 rows\n\n\nNames:\n\n\nnames(surveys) - returns the column names (synonym of colnames() for data.frame objects)\n\nrownames(surveys) - returns the row names\n\n\nSummary:\n\n\nstr(surveys) - structure of the object and information about the class, length and content of each column\n\nsummary(surveys) - summary statistics for each column\n\n\n\nNote: most of these functions are ‚Äúgeneric‚Äù, they can be used on other types of objects besides data.frame.\n\nChallenge\nBased on the output of str(surveys), can you answer the following questions?\n\nWhat is the class of the object surveys?\nHow many rows and how many columns are in this object?\n\n\n\n\nAnswer\n\n\nstr(surveys)\n\n#> spec_tbl_df [34,786 √ó 13] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n#>  $ record_id      : num [1:34786] 1 72 224 266 349 363 435 506 588 661 ...\n#>  $ month          : num [1:34786] 7 8 9 10 11 11 12 1 2 3 ...\n#>  $ day            : num [1:34786] 16 19 13 16 12 12 10 8 18 11 ...\n#>  $ year           : num [1:34786] 1977 1977 1977 1977 1977 ...\n#>  $ plot_id        : num [1:34786] 2 2 2 2 2 2 2 2 2 2 ...\n#>  $ species_id     : chr [1:34786] \"NL\" \"NL\" \"NL\" \"NL\" ...\n#>  $ sex            : chr [1:34786] \"M\" \"M\" NA NA ...\n#>  $ hindfoot_length: num [1:34786] 32 31 NA NA NA NA NA NA NA NA ...\n#>  $ weight         : num [1:34786] NA NA NA NA NA NA NA NA 218 NA ...\n#>  $ genus          : chr [1:34786] \"Neotoma\" \"Neotoma\" \"Neotoma\" \"Neotoma\" ...\n#>  $ species        : chr [1:34786] \"albigula\" \"albigula\" \"albigula\" \"albigula\" ...\n#>  $ taxa           : chr [1:34786] \"Rodent\" \"Rodent\" \"Rodent\" \"Rodent\" ...\n#>  $ plot_type      : chr [1:34786] \"Control\" \"Control\" \"Control\" \"Control\" ...\n#>  - attr(*, \"spec\")=\n#>   .. cols(\n#>   ..   record_id = col_double(),\n#>   ..   month = col_double(),\n#>   ..   day = col_double(),\n#>   ..   year = col_double(),\n#>   ..   plot_id = col_double(),\n#>   ..   species_id = col_character(),\n#>   ..   sex = col_character(),\n#>   ..   hindfoot_length = col_double(),\n#>   ..   weight = col_double(),\n#>   ..   genus = col_character(),\n#>   ..   species = col_character(),\n#>   ..   taxa = col_character(),\n#>   ..   plot_type = col_character()\n#>   .. )\n#>  - attr(*, \"problems\")=<externalptr>\n\n## * class: data frame\n## * how many rows: 34786,  how many columns: 13"
  },
  {
    "objectID": "02-starting-with-data.html#indexing-and-subsetting-data-frames",
    "href": "02-starting-with-data.html#indexing-and-subsetting-data-frames",
    "title": "Starting with data",
    "section": "Indexing and subsetting data frames",
    "text": "Indexing and subsetting data frames\n\n\n\nOur survey data frame has rows and columns (it has 2 dimensions), if we want to extract some specific data from it, we need to specify the ‚Äúcoordinates‚Äù we want from it. Row numbers come first, followed by column numbers. However, note that different ways of specifying these coordinates lead to results with different classes.\n\n# We can extract specific values by specifying row and column indices\n# in the format: \n# data_frame[row_index, column_index]\n# For instance, to extract the first row and column from surveys:\nsurveys[1, 1]\n\n# First row, sixth column:\nsurveys[1, 6]   \n\n# We can also use shortcuts to select a number of rows or columns at once\n# To select all columns, leave the column index blank\n# For instance, to select all columns for the first row:\nsurveys[1, ]\n\n# The same shortcut works for rows --\n# To select the first column across all rows:\nsurveys[, 1]\n\n# An even shorter way to select first column across all rows:\nsurveys[1] # No comma! \n\n# To select multiple rows or columns, use vectors!\n# To select the first three rows of the 5th and 6th column\nsurveys[c(1, 2, 3), c(5, 6)] \n\n# We can use the : operator to create those vectors for us:\nsurveys[1:3, 5:6] \n\n# This is equivalent to head_surveys <- head(surveys)\nhead_surveys <- surveys[1:6, ]\n\n# As we've seen, when working with tibbles \n# subsetting with single square brackets (\"[]\") always returns a data frame.\n# If you want a vector, use double square brackets (\"[[]]\")\n\n# For instance, to get the first column as a vector:\nsurveys[[1]]\n\n# To get the first value in our data frame:\nsurveys[[1, 1]]\n\n: is a special function that creates numeric vectors of integers in increasing or decreasing order, test 1:10 and 10:1 for instance.\nYou can also exclude certain indices of a data frame using the ‚Äú-‚Äù sign:\n\nsurveys[, -1]                 # The whole data frame, except the first column\nsurveys[-(7:nrow(surveys)), ] # Equivalent to head(surveys)\n\nData frames can be subset by calling indices (as shown previously), but also by calling their column names directly:\n\n# As before, using single brackets returns a data frame:\nsurveys[\"species_id\"]\nsurveys[, \"species_id\"]\n\n# Double brackets returns a vector:\nsurveys[[\"species_id\"]]\n\n# We can also use the $ operator with column names instead of double brackets\n# This returns a vector:\nsurveys$species_id\n\nIn RStudio, you can use the autocompletion feature to get the full and correct names of the columns.\n\nChallenge\n\nCreate a data.frame (surveys_200) containing only the data in row 200 of the surveys dataset.\n\nNotice how nrow() gave you the number of rows in a data.frame?\n\nUse that number to pull out just that last row from the surveys dataset.\nCompare that with what you see as the last row using tail() to make sure it‚Äôs meeting expectations.\nPull out that last row using nrow() instead of the row number.\nCreate a new data frame (surveys_last) from that last row.\n\n\nUse nrow() to extract the row that is in the middle of the data frame. Store the content of this row in an object named surveys_middle.\nCombine nrow() with the - notation above to reproduce the behavior of head(surveys), keeping just the first through 6th rows of the surveys dataset.\n\n\n\n\nAnswer\n\n\n## 1.\nsurveys_200 <- surveys[200, ]\n## 2.\n# Saving `n_rows` to improve readability and reduce duplication\nn_rows <- nrow(surveys)\nsurveys_last <- surveys[n_rows, ]\n## 3.\nsurveys_middle <- surveys[n_rows / 2, ]\n## 4.\nsurveys_head <- surveys[-(7:n_rows), ]"
  },
  {
    "objectID": "02-starting-with-data.html#factors",
    "href": "02-starting-with-data.html#factors",
    "title": "Starting with data",
    "section": "Factors",
    "text": "Factors\n\n\n\nWhen we did str(surveys) we saw that several of the columns consist of integers. The columns genus, species, sex, plot_type, ‚Ä¶ however, are of the class character. Arguably, these columns contain categorical data, that is, they can only take on a limited number of values.\nR has a special class for working with categorical data, called factor. Factors are very useful and actually contribute to making R particularly well suited to working with data. So we are going to spend a little time introducing them.\nOnce created, factors can only contain a pre-defined set of values, known as levels. Factors are stored as integers associated with labels and they can be ordered or unordered. While factors look (and often behave) like character vectors, they are actually treated as integer vectors by R. So you need to be very careful when treating them as strings.\nWhen importing a data frame with read_csv(), the columns that contain text are not automatically coerced (=converted) into the factor data type, but once we have loaded the data we can do the conversion using the factor() function:\n\nsurveys$sex <- factor(surveys$sex)\n\nWe can see that the conversion has worked by using the summary() function again. This produces a table with the counts for each factor level:\n\nsummary(surveys$sex)\n\nBy default, R always sorts levels in alphabetical order. For instance, if you have a factor with 2 levels:\n\nsex <- factor(c(\"male\", \"female\", \"female\", \"male\"))\n\nR will assign 1 to the level \"female\" and 2 to the level \"male\" (because f comes before m, even though the first element in this vector is \"male\"). You can see this by using the function levels() and you can find the number of levels using nlevels():\n\nlevels(sex)\nnlevels(sex)\n\nSometimes, the order of the factors does not matter, other times you might want to specify the order because it is meaningful (e.g., ‚Äúlow‚Äù, ‚Äúmedium‚Äù, ‚Äúhigh‚Äù), it improves your visualization, or it is required by a particular type of analysis. Here, one way to reorder our levels in the sex vector would be:\n\nsex # current order\n\n#> [1] male   female female male  \n#> Levels: female male\n\nsex <- factor(sex, levels = c(\"male\", \"female\"))\nsex # after re-ordering\n\n#> [1] male   female female male  \n#> Levels: male female\n\n\nIn R‚Äôs memory, these factors are represented by integers (1, 2, 3), but are more informative than integers because factors are self describing: \"female\", \"male\" is more descriptive than 1, 2. Which one is ‚Äúmale‚Äù? You wouldn‚Äôt be able to tell just from the integer data. Factors, on the other hand, have this information built in. It is particularly helpful when there are many levels (like the species names in our example dataset).\n\nChallenge\n\nChange the columns taxa and genus in the surveys data frame into a factor.\n\nUsing the functions you learned before, can you find out‚Ä¶\n\nHow many rabbits were observed?\nHow many different genera are in the genus column?\n\n\n\n\n\n\nAnswer\n\n\nsurveys$taxa <- factor(surveys$taxa)\nsurveys$genus <- factor(surveys$genus)\nsummary(surveys)\nnlevels(surveys$genus)\n\n## * how many genera: There are 26 unique genera in the `genus` column.\n## * how many rabbts: There are 75 rabbits in the `taxa` column.\n\n\n\n\n\n\n\nConverting factors\nIf you need to convert a factor to a character vector, you use as.character(x).\n\nas.character(sex)\n\nIn some cases, you may have to convert factors where the levels appear as numbers (such as concentration levels or years) to a numeric vector. For instance, in one part of your analysis the years might need to be encoded as factors (e.g., comparing average weights across years) but in another part of your analysis they may need to be stored as numeric values (e.g., doing math operations on the years). This conversion from factor to numeric is a little trickier. The as.numeric() function returns the index values of the factor, not its levels, so it will result in an entirely new (and unwanted in this case) set of numbers. One method to avoid this is to convert factors to characters, and then to numbers.\nAnother method is to use the levels() function. Compare:\n\nyear_fct <- factor(c(1990, 1983, 1977, 1998, 1990))\nas.numeric(year_fct)               # Wrong! And there is no warning...\nas.numeric(as.character(year_fct)) # Works...\nas.numeric(levels(year_fct))[year_fct]    # The recommended way.\n\nNotice that in the levels() approach, three important steps occur:\n\nWe obtain all the factor levels using levels(year_fct)\n\nWe convert these levels to numeric values using as.numeric(levels(year_fct))\n\nWe then access these numeric values using the underlying integers of the vector year_fct inside the square brackets\nRenaming factors\nWhen your data is stored as a factor, you can use the plot() function to get a quick glance at the number of observations represented by each factor level. Let‚Äôs look at the number of males and females captured over the course of the experiment:\n\n## bar plot of the number of females and males captured during the experiment:\nplot(surveys$sex)\n\n\n\n\nHowever, as we saw when we used summary(surveys$sex), there are about 1700 individuals for which the sex information hasn‚Äôt been recorded. To show them in the plot, we can turn the missing values into a factor level with the addNA() function. We will also have to give the new factor level a label. We are going to work with a copy of the sex column, so we‚Äôre not modifying the working copy of the data frame:\n\nsex <- surveys$sex\nlevels(sex)\n\n#> [1] \"F\" \"M\"\n\nsex <- addNA(sex)\nlevels(sex)\n\n#> [1] \"F\" \"M\" NA\n\nhead(sex)\n\n#> [1] M    M    <NA> <NA> <NA> <NA>\n#> Levels: F M <NA>\n\nlevels(sex)[3] <- \"undetermined\"\nlevels(sex)\n\n#> [1] \"F\"            \"M\"            \"undetermined\"\n\nhead(sex)\n\n#> [1] M            M            undetermined undetermined undetermined\n#> [6] undetermined\n#> Levels: F M undetermined\n\n\nNow we can plot the data again, using plot(sex).\n\n\n\n\n\n\nChallenge\n\nRename ‚ÄúF‚Äù and ‚ÄúM‚Äù to ‚Äúfemale‚Äù and ‚Äúmale‚Äù respectively.\nNow that we have renamed the factor level to ‚Äúundetermined‚Äù, can you recreate the barplot such that ‚Äúundetermined‚Äù is first (before ‚Äúfemale‚Äù)?\n\n\n\n\nAnswer\n\n\nlevels(sex)[1:2] <- c(\"female\", \"male\")\nsex <- factor(sex, levels = c(\"undetermined\", \"female\", \"male\"))\nplot(sex)\n\n\n\n\n\n\n\n\n\n\n\nChallenge\n\n\nWe have seen how data frames are created when using read_csv(), but they can also be created by hand with the data.frame() function. There are a few mistakes in this hand-crafted data.frame. Can you spot and fix them? Don‚Äôt hesitate to experiment!\n::: {.cell}\nanimal_data <- data.frame(\n          animal = c(dog, cat, sea cucumber, sea urchin),\n          feel = c(\"furry\", \"squishy\", \"spiny\"),\n          weight = c(45, 8 1.1, 0.8)\n          )\n:::\n::: {.cell}\n:::\n\n\nCan you predict the class for each of the columns in the following example? Check your guesses using str(country_climate):\n\nAre they what you expected? Why? Why not?\nWhat would you need to change to ensure that each column had the accurate data type?\n\n::: {.cell}\ncountry_climate <- data.frame(\n       country = c(\"Canada\", \"Panama\", \"South Africa\", \"Australia\"),\n       climate = c(\"cold\", \"hot\", \"temperate\", \"hot/temperate\"),\n       temperature = c(10, 30, 18, \"15\"),\n       northern_hemisphere = c(TRUE, TRUE, FALSE, \"FALSE\"),\n       has_kangaroo = c(FALSE, FALSE, FALSE, 1)\n       )\n:::\n\n\n\n::: {.cell}\n\n\n\nAnswer\n\n\n\n\n\nmissing quotations around the names of the animals\nmissing one entry in the feel column (probably for one of the furry animals)\nmissing one comma in the weight column\n\ncountry, climate, temperature, and northern_hemisphere are characters; has_kangaroo is numeric\nusing factor() one could replace character columns with factors columns\nremoving the quotes in temperature and northern_hemisphere and replacing 1 by TRUE in the has_kangaroo column would give what was probably intended\n\n\n\n\n\n\n\n:::\n\n\nThe automatic conversion of data type is sometimes a blessing, sometimes an annoyance. Be aware that it exists, learn the rules, and double check that data you import in R are of the correct type within your data frame. If not, use it to your advantage to detect mistakes that might have been introduced during data entry (for instance, a letter in a column that should only contain numbers).\nLearn more in this RStudio tutorial"
  },
  {
    "objectID": "02-starting-with-data.html#formatting-dates",
    "href": "02-starting-with-data.html#formatting-dates",
    "title": "Starting with data",
    "section": "Formatting dates",
    "text": "Formatting dates\nA common issue that new (and experienced!) R users have is converting date and time information into a variable that is suitable for analyses. One way to store date information is to store each component of the date in a separate column. Using str(), we can confirm that our data frame does indeed have a separate column for day, month, and year, and that each of these columns contains integer values.\n\nstr(surveys)\n\nWe are going to use the ymd() function from the package lubridate (which belongs to the tidyverse; learn more here). lubridate gets installed as part as the tidyverse installation. When you load the tidyverse (library(tidyverse)), the core packages (the packages used in most data analyses) get loaded. lubridate however does not belong to the core tidyverse, so you have to load it explicitly with library(lubridate)\nStart by loading the required package:\n\nlibrary(lubridate)\n\nThe lubridate package has many useful functions for working with dates. These can help you extract dates from different string representations, convert between timezones, calculate time differences and more. You can find an overview of them in the lubridate cheat sheet.\nHere we will use the function ymd(), which takes a vector representing year, month, and day, and converts it to a Date vector. Date is a class of data recognized by R as being a date and can be manipulated as such. The argument that the function requires is flexible, but, as a best practice, is a character vector formatted as ‚ÄúYYYY-MM-DD‚Äù.\nLet‚Äôs create a date object and inspect the structure:\n\nmy_date <- ymd(\"2015-01-01\")\nstr(my_date)\n\nNow let‚Äôs paste the year, month, and day separately - we get the same result:\n\n# sep indicates the character to use to separate each component\nmy_date <- ymd(paste(\"2015\", \"1\", \"1\", sep = \"-\")) \nstr(my_date)\n\nNow we apply this function to the surveys dataset. Create a character vector from the year, month, and day columns of surveys using paste():\n\npaste(surveys$year, surveys$month, surveys$day, sep = \"-\")\n\nThis character vector can be used as the argument for ymd():\n\nymd(paste(surveys$year, surveys$month, surveys$day, sep = \"-\"))\n\n#> Warning: 129 failed to parse.\n\n\nThere is a warning telling us that some dates could not be parsed (understood) by the ymd() function. For these dates, the function has returned NA, which means they are treated as missing values. We will deal with this problem later, but first we add the resulting Date vector to the surveys data frame as a new column called date:\n\nsurveys$date <- ymd(paste(surveys$year, surveys$month, surveys$day, sep = \"-\"))\n\n#> Warning: 129 failed to parse.\n\nstr(surveys) # notice the new column, with 'date' as the class\n\nLet‚Äôs make sure everything worked correctly. One way to inspect the new column is to use summary():\n\nsummary(surveys$date)\n\n#>         Min.      1st Qu.       Median         Mean      3rd Qu.         Max. \n#> \"1977-07-16\" \"1984-03-12\" \"1990-07-22\" \"1990-12-15\" \"1997-07-29\" \"2002-12-31\" \n#>         NA's \n#>        \"129\"\n\n\nLet‚Äôs investigate why some dates could not be parsed.\nWe can use the functions we saw previously to deal with missing data to identify the rows in our data frame that are failing. If we combine them with what we learned about subsetting data frames earlier, we can extract the columns ‚Äúyear,‚Äùmonth‚Äù, ‚Äúday‚Äù from the records that have NA in our new column date. We will also use head() so we don‚Äôt clutter the output:\n\nmissing_dates <- surveys[is.na(surveys$date), c(\"year\", \"month\", \"day\")]\n\nhead(missing_dates)\n\n#> # A tibble: 6 √ó 3\n#>    year month   day\n#>   <dbl> <dbl> <dbl>\n#> 1  2000     9    31\n#> 2  2000     4    31\n#> 3  2000     4    31\n#> 4  2000     4    31\n#> 5  2000     4    31\n#> 6  2000     9    31\n\n\nWhy did these dates fail to parse? If you had to use these data for your analyses, how would you deal with this situation?\nThe answer is because the dates provided as input for the ymd() function do not actually exist. If we refer to the output we got above, September and April only have 30 days, not 31 days as it is specified in our dataset.\nThere are several ways you could deal with situation: * If you have access to the raw data (e.g., field sheets) or supporting information (e.g., field trip reports/logs), check them and ensure the electronic database matches the information in the original data source. * If you are able to contact the person responsible for collecting the data, you could refer to them and ask for clarification. * You could also check the rest of the dataset for clues about the correct value for the erroneous dates. * If your project has guidelines on how to correct this sort of errors, refer to them and apply any recommendations. * If it is not possible to ascertain the correct value for these observations, you may want to leave them as missing data.\nRegardless of the option you choose, it is important that you document the error and the corrections (if any) that you apply to your data.\n\nPage built on: üìÜ 2022-06-28 ‚Äí üï¢ 17:22:36"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Instructor",
    "section": "",
    "text": "Brady Johnston\n\nCurrently writing PhD thesis (almost there‚Ä¶) in Structural Biology and Biophysics\nPart-time data scientist with the Minderoo Foundation\n\nI‚Äôm a self-taught coder, first learning R to do data analysis for my PhD and now regularly write Python & Julia code for various projects, and I get paid to write R code for the Minderoo foundation.\nI‚Äôve written multiple R packages, and am currently developing a suite of tools for protein visualisation inside of the 3D animation package Blender. You can see more about my different software projects on my github and I post about my different data vis experiments on my twitter.\n\n\nI have now added support for importing full-blown MD topology & trajectory files, from the likes of GROMACS & CHARMM straight into #blender3d! Along with a few other UI & under-the-hood improvements, download v0.5.15 now!https://t.co/qcu3MWGOUc#geometrynodes #3d pic.twitter.com/ybXc8suIyC\n\n‚Äî Brady Johnston (@bradyajohnston) May 23, 2022\n\n\n\n\nI have managed to create a #blender3d plugin for quickly and easily getting structural biology data into #blender! It supports models and MD trajectories, and once you have the atoms inside of #geometrynodes, you can creative!Check it out: https://t.co/wRSjIeUhcR pic.twitter.com/NwPjA7OE5o\n\n‚Äî Brady Johnston (@bradyajohnston) April 27, 2022\n\n\n\n\nMy first #tidytuesday post. Showing the top 5 companies with trash in the dataset. Animation showing movement from their HQ location to the country it was found in. More dots = more trash.Play with it yourself and see the code:https://t.co/fa51dFdIpH pic.twitter.com/a7x7OGZWU4\n\n‚Äî Brady Johnston (@bradyajohnston) January 31, 2021"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "Centre for Applied Bioinformatics R Workshop",
    "section": "",
    "text": "All Data Carpentry instructional material is made available under the Creative Commons Attribution license. You are free:\n\nto Share‚Äîto copy, distribute and transmit the work\nto Remix‚Äîto adapt the work\n\nUnder the following conditions:\n\n\nAttribution‚ÄîYou must attribute the work using ‚ÄúCopyright (c) Data Carpentry‚Äù (but not in any way that suggests that we endorse you or your use of the work). Where practical, you must also include a hyperlink to https://datacarpentry.org.\n\nWith the understanding that:\n\n\nWaiver‚ÄîAny of the above conditions can be waived if you get permission from the copyright holder.\n\nOther Rights‚ÄîIn no way are any of the following rights affected by the license:\n\nYour fair dealing or fair use rights;\nThe author‚Äôs moral rights;\nRights other persons may have either in the work itself or in how the work is used, such as publicity or privacy rights. *\n\n\n\nNotice‚ÄîFor any reuse or distribution, you must make clear to others the license terms of this work. The best way to do this is with a link to https://creativecommons.org/licenses/by/4.0/.\n\nFor the full legal text of this license, please see https://creativecommons.org/licenses/by/4.0/legalcode.\n\nExcept where otherwise noted, the example programs and other software provided by Data Carpentry are made available under the OSI-approved MIT license.\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ‚ÄúSoftware‚Äù), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED ‚ÄúAS IS‚Äù, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nPage built on: üìÜ 2022-06-28 ‚Äí üï¢ 17:22:42"
  },
  {
    "objectID": "01-intro-to-r.html#creating-objects-in-r",
    "href": "01-intro-to-r.html#creating-objects-in-r",
    "title": "Introduction to R",
    "section": "Creating objects in R",
    "text": "Creating objects in R\n\n\n\nYou can get output from R simply by typing math in the console:\n\n3 + 5\n12 / 7\n\nHowever, to do useful and interesting things, we need to assign values to objects. To create an object, we need to give it a name followed by the assignment operator <-, and the value we want to give it:\n\nweight_kg <- 55\n\n<- is the assignment operator. It assigns values on the right to objects on the left. So, after executing x <- 3, the value of x is 3. For historical reasons, you can also use = for assignments, but not in every context. Because of the slight differences in syntax, it is good practice to always use <- for assignments.\nIn RStudio, typing Alt + - (push Alt at the same time as the - key) will write <- in a single keystroke in a PC, while typing Option + - (push Option at the same time as the - key) does the same in a Mac.\nObjects can be given almost any name such as x, current_temperature, or subject_id. Here are some further guidelines on naming objects:\n\nYou want your object names to be explicit and not too long.\nThey cannot start with a number (2x is not valid, but x2 is).\nR is case sensitive, so for example, weight_kg is different from Weight_kg.\nThere are some names that cannot be used because they are the names of fundamental functions in R (e.g., if, else, for, see here for a complete list). In general, even if it‚Äôs allowed, it‚Äôs best to not use other function names (e.g., c, T, mean, data, df, weights). If in doubt, check the help to see if the name is already in use.\nIt‚Äôs best to avoid dots (.) within names. Many function names in R itself have them and dots also have a special meaning (methods) in R and other programming languages. To avoid confusion, don‚Äôt include dots in names.\nIt is recommended to use nouns for object names and verbs for function names.\nBe consistent in the styling of your code, such as where you put spaces, how you name objects, etc. Styles can include ‚Äúlower_snake‚Äù, ‚ÄúUPPER_SNAKE‚Äù, ‚ÄúlowerCamelCase‚Äù, ‚ÄúUpperCamelCase‚Äù, etc. Using a consistent coding style makes your code clearer to read for your future self and your collaborators. In R, three popular style guides come from Google, Jean Fan and the tidyverse. The tidyverse style is very comprehensive and may seem overwhelming at first. You can install the lintr package to automatically check for issues in the styling of your code.\n\nObjects vs.¬†variables\nWhat are known as objects in R are known as variables in many other programming languages. Depending on the context, object and variable can have drastically different meanings. However, in this lesson, the two words are used synonymously. For more information see: https://cran.r-project.org/doc/manuals/r-release/R-lang.html#Objects\nWhen assigning a value to an object, R does not print anything. You can force R to print the value by using parentheses or by typing the object name:\n\nweight_kg <- 55    # doesn't print anything\n(weight_kg <- 55)  # but putting parenthesis around the call prints the value of `weight_kg`\nweight_kg          # and so does typing the name of the object\n\nNow that R has weight_kg in memory, we can do arithmetic with it. For instance, we may want to convert this weight into pounds (weight in pounds is 2.2 times the weight in kg):\n\n2.2 * weight_kg\n\nWe can also change an object‚Äôs value by assigning it a new one:\n\nweight_kg <- 57.5\n2.2 * weight_kg\n\nThis means that assigning a value to one object does not change the values of other objects. For example, let‚Äôs store the animal‚Äôs weight in pounds in a new object, weight_lb:\n\nweight_lb <- 2.2 * weight_kg\n\nand then change weight_kg to 100.\n\nweight_kg <- 100\n\nWhat do you think is the current content of the object weight_lb? 126.5 or 220?\nSaving your code\nUp to now, your code has been in the console. This is useful for quick queries but not so helpful if you want to revisit your work for any reason. A script can be opened by pressing Ctrl + Shift + N. It is wise to save your script file immediately. To do this press Ctrl + S. This will open a dialogue box where you can decide where to save your script file, and what to name it. The .R file extension is added automatically and ensures your file will open with RStudio.\nDon‚Äôt forget to save your work periodically by pressing Ctrl + S.\nComments\nThe comment character in R is #. Anything to the right of a # in a script will be ignored by R. It is useful to leave notes and explanations in your scripts. For convenience, RStudio provides a keyboard shortcut to comment or uncomment a paragraph: after selecting the lines you want to comment, press at the same time on your keyboard Ctrl + Shift + C. If you only want to comment out one line, you can put the cursor at any location of that line (i.e.¬†no need to select the whole line), then press Ctrl + Shift + C.\nChallenge\nWhat are the values after each statement in the following?\n\nmass <- 47.5            # mass?\nage  <- 122             # age?\nmass <- mass * 2.0      # mass?\nage  <- age - 20        # age?\nmass_index <- mass/age  # mass_index?\n\n\n\n\nFunctions and their arguments\nFunctions are ‚Äúcanned scripts‚Äù that automate more complicated sets of commands including operations assignments, etc. Many functions are predefined, or can be made available by importing R packages (more on that later). A function usually takes one or more inputs called arguments. Functions often (but not always) return a value. A typical example would be the function sqrt(). The input (the argument) must be a number, and the return value (in fact, the output) is the square root of that number. Executing a function (‚Äòrunning it‚Äô) is called calling the function. An example of a function call is:\n\nweight_kg <- sqrt(10)\n\nHere, the value of 10 is given to the sqrt() function, the sqrt() function calculates the square root, and returns the value which is then assigned to the object weight_kg. This function takes one argument, other functions might take several.\nThe return ‚Äòvalue‚Äô of a function need not be numerical (like that of sqrt()), and it also does not need to be a single item: it can be a set of things, or even a dataset. We‚Äôll see that when we read data files into R.\nArguments can be anything, not only numbers or filenames, but also other objects. Exactly what each argument means differs per function, and must be looked up in the documentation (see below). Some functions take arguments which may either be specified by the user, or, if left out, take on a default value: these are called options. Options are typically used to alter the way the function operates, such as whether it ignores ‚Äòbad values‚Äô, or what symbol to use in a plot. However, if you want something specific, you can specify a value of your choice which will be used instead of the default.\nLet‚Äôs try a function that can take multiple arguments: round().\n\nround(3.14159)\n\n#> [1] 3\n\n\nHere, we‚Äôve called round() with just one argument, 3.14159, and it has returned the value 3. That‚Äôs because the default is to round to the nearest whole number. If we want more digits we can see how to do that by getting information about the round function. We can use args(round) to find what arguments it takes, or look at the help for this function using ?round.\n\nargs(round)\n\n#> function (x, digits = 0) \n#> NULL\n\n\n\n?round\n\nWe see that if we want a different number of digits, we can type digits = 2 or however many we want.\n\nround(3.14159, digits = 2)\n\n#> [1] 3.14\n\n\nIf you provide the arguments in the exact same order as they are defined you don‚Äôt have to name them:\n\nround(3.14159, 2)\n\n#> [1] 3.14\n\n\nAnd if you do name the arguments, you can switch their order:\n\nround(digits = 2, x = 3.14159)\n\n#> [1] 3.14\n\n\nIt‚Äôs good practice to put the non-optional arguments (like the number you‚Äôre rounding) first in your function call, and to then specify the names of all optional arguments. If you don‚Äôt, someone reading your code might have to look up the definition of a function with unfamiliar arguments to understand what you‚Äôre doing."
  },
  {
    "objectID": "01-intro-to-r.html#vectors-and-data-types",
    "href": "01-intro-to-r.html#vectors-and-data-types",
    "title": "Introduction to R",
    "section": "Vectors and data types",
    "text": "Vectors and data types\n\n\n\nA vector is the most common and basic data type in R, and is pretty much the workhorse of R. A vector is composed by a series of values, which can be either numbers or characters. We can assign a series of values to a vector using the c() function. For example we can create a vector of animal weights and assign it to a new object weight_g:\n\nweight_g <- c(50, 60, 65, 82)\nweight_g\n\nA vector can also contain characters:\n\nanimals <- c(\"mouse\", \"rat\", \"dog\")\nanimals\n\nThe quotes around ‚Äúmouse‚Äù, ‚Äúrat‚Äù, etc. are essential here. Without the quotes R will assume objects have been created called mouse, rat and dog. As these objects don‚Äôt exist in R‚Äôs memory, there will be an error message.\nThere are many functions that allow you to inspect the content of a vector. length() tells you how many elements are in a particular vector:\n\nlength(weight_g)\nlength(animals)\n\nAn important feature of a vector, is that all of the elements are the same type of data. The function class() indicates what kind of object you are working with:\n\nclass(weight_g)\nclass(animals)\n\nThe function str() provides an overview of the structure of an object and its elements. It is a useful function when working with large and complex objects:\n\nstr(weight_g)\nstr(animals)\n\nYou can use the c() function to add other elements to your vector:\n\nweight_g <- c(weight_g, 90) # add to the end of the vector\nweight_g <- c(30, weight_g) # add to the beginning of the vector\nweight_g\n\nIn the first line, we take the original vector weight_g, add the value 90 to the end of it, and save the result back into weight_g. Then we add the value 30 to the beginning, again saving the result back into weight_g.\nWe can do this over and over again to grow a vector, or assemble a dataset. As we program, this may be useful to add results that we are collecting or calculating.\nAn atomic vector is the simplest R data type and is a linear vector of a single type. Above, we saw 2 of the 6 main atomic vector types that R uses: \"character\" and \"numeric\" (or \"double\"). These are the basic building blocks that all R objects are built from. The other 4 atomic vector types are:\n\n\n\"logical\" for TRUE and FALSE (the boolean data type)\n\n\"integer\" for integer numbers (e.g., 2L, the L indicates to R that it‚Äôs an integer)\n\n\"complex\" to represent complex numbers with real and imaginary parts (e.g., 1 + 4i) and that‚Äôs all we‚Äôre going to say about them\n\n\"raw\" for bitstreams that we won‚Äôt discuss further\n\nYou can check the type of your vector using the typeof() function and inputting your vector as the argument.\nVectors are one of the many data structures that R uses. Other important ones are lists (list), matrices (matrix), data frames (data.frame), factors (factor) and arrays (array).\nChallenge\n\nWe‚Äôve seen that atomic vectors can be of type character, numeric (or double), integer, and logical. But what happens if we try to mix these types in a single vector?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nR implicitly converts them to all be the same type\n\n\n\n\n\nWhat will happen in each of these examples? (hint: use class() to check the data type of your objects):\nnum_char <- c(1, 2, 3, \"a\")\nnum_logical <- c(1, 2, 3, TRUE)\nchar_logical <- c(\"a\", \"b\", \"c\", TRUE)\ntricky <- c(1, 2, 3, \"4\")\n\nWhy do you think it happens?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nVectors can be of only one data type. R tries to convert (coerce) the content of this vector to find a ‚Äúcommon denominator‚Äù that doesn‚Äôt lose any information.\n\n\n\n\nHow many values in combined_logical are \"TRUE\" (as a character) in the following example (reusing the 2 ..._logicals from above):\n\ncombined_logical <- c(num_logical, char_logical)\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nOnly one. There is no memory of past data types, and the coercion happens the first time the vector is evaluated. Therefore, the TRUE in num_logical gets converted into a 1 before it gets converted into \"1\" in combined_logical.\n\n\n\n\nYou‚Äôve probably noticed that objects of different types get converted into a single, shared type within a vector. In R, we call converting objects from one class into another class coercion. These conversions happen according to a hierarchy, whereby some types get preferentially coerced into other types. Can you draw a diagram that represents the hierarchy of how these data types are coerced?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nlogical ‚Üí numeric ‚Üí character ‚Üê logical"
  },
  {
    "objectID": "01-intro-to-r.html#subsetting-vectors",
    "href": "01-intro-to-r.html#subsetting-vectors",
    "title": "Introduction to R",
    "section": "Subsetting vectors",
    "text": "Subsetting vectors\nIf we want to extract one or several values from a vector, we must provide one or several indices in square brackets. For instance:\n\nanimals <- c(\"mouse\", \"rat\", \"dog\", \"cat\")\nanimals[2]\n\n#> [1] \"rat\"\n\nanimals[c(3, 2)]\n\n#> [1] \"dog\" \"rat\"\n\n\nWe can also repeat the indices to create an object with more elements than the original one:\n\nmore_animals <- animals[c(1, 2, 3, 2, 1, 4)]\nmore_animals\n\n#> [1] \"mouse\" \"rat\"   \"dog\"   \"rat\"   \"mouse\" \"cat\"\n\n\nR indices start at 1. Programming languages like Fortran, MATLAB, Julia, and R start counting at 1, because that‚Äôs what human beings typically do. Languages in the C family (including C++, Java, Perl, and Python) count from 0 because that‚Äôs simpler for computers to do.\nConditional subsetting\nAnother common way of subsetting is by using a logical vector. TRUE will select the element with the same index, while FALSE will not:\n\nweight_g <- c(21, 34, 39, 54, 55)\nweight_g[c(TRUE, FALSE, FALSE, TRUE, TRUE)]\n\n#> [1] 21 54 55\n\n\nTypically, these logical vectors are not typed by hand, but are the output of other functions or logical tests. For instance, if you wanted to select only the values above 50:\n\nweight_g > 50    # will return logicals with TRUE for the indices that meet the condition\n\n#> [1] FALSE FALSE FALSE  TRUE  TRUE\n\n## so we can use this to select only the values above 50\nweight_g[weight_g > 50]\n\n#> [1] 54 55\n\n\nYou can combine multiple tests using & (both conditions are true, AND) or | (at least one of the conditions is true, OR):\n\nweight_g[weight_g > 30 & weight_g < 50]\n\n#> [1] 34 39\n\nweight_g[weight_g <= 30 | weight_g == 55]\n\n#> [1] 21 55\n\nweight_g[weight_g >= 30 & weight_g == 21]\n\n#> numeric(0)\n\n\nHere, > for ‚Äúgreater than‚Äù, < stands for ‚Äúless than‚Äù, <= for ‚Äúless than or equal to‚Äù, and == for ‚Äúequal to‚Äù. The double equal sign == is a test for numerical equality between the left and right hand sides, and should not be confused with the single = sign, which performs variable assignment (similar to <-).\nA common task is to search for certain strings in a vector. One could use the ‚Äúor‚Äù operator | to test for equality to multiple values, but this can quickly become tedious. The function %in% allows you to test if any of the elements of a search vector are found:\n\nanimals <- c(\"mouse\", \"rat\", \"dog\", \"cat\", \"cat\")\n\n# return both rat and cat\nanimals[animals == \"cat\" | animals == \"rat\"]\n\n#> [1] \"rat\" \"cat\" \"cat\"\n\n# return a logical vector that is TRUE for the elements within animals\n# that are found in the character vector and FALSE for those that are not\nanimals %in% c(\"rat\", \"cat\", \"dog\", \"duck\", \"goat\", \"bird\", \"fish\")\n\n#> [1] FALSE  TRUE  TRUE  TRUE  TRUE\n\n# use the logical vector created by %in% to return elements from animals\n# that are found in the character vector\nanimals[animals %in% c(\"rat\", \"cat\", \"dog\", \"duck\", \"goat\", \"bird\", \"fish\")]\n\n#> [1] \"rat\" \"dog\" \"cat\" \"cat\"\n\n\nChallenge (optional)\n\nCan you figure out why \"four\" > \"five\" returns TRUE?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWhen using ‚Äú>‚Äù or ‚Äú<‚Äù on strings, R compares their alphabetical order. Here ‚Äúfour‚Äù comes after ‚Äúfive‚Äù, and therefore is ‚Äúgreater than‚Äù it."
  },
  {
    "objectID": "01-intro-to-r.html#missing-data",
    "href": "01-intro-to-r.html#missing-data",
    "title": "Introduction to R",
    "section": "Missing data",
    "text": "Missing data\nAs R was designed to analyze datasets, it includes the concept of missing data (which is uncommon in other programming languages). Missing data are represented in vectors as NA.\nWhen doing operations on numbers, most functions will return NA if the data you are working with include missing values. This feature makes it harder to overlook the cases where you are dealing with missing data. You can add the argument na.rm = TRUE to calculate the result as if the missing values were removed (rm stands for ReMoved) first.\n\nheights <- c(2, 4, 4, NA, 6)\nmean(heights)\nmax(heights)\nmean(heights, na.rm = TRUE)\nmax(heights, na.rm = TRUE)\n\nIf your data include missing values, you may want to become familiar with the functions is.na(), na.omit(), and complete.cases(). See below for examples.\n\n## Extract those elements which are not missing values.\nheights[!is.na(heights)]\n\n## Returns the object with incomplete cases removed.\n#The returned object is an atomic vector of type `\"numeric\"` (or #`\"double\"`).\nna.omit(heights)\n\n## Extract those elements which are complete cases.\n#The returned object is an atomic vector of type `\"numeric\"` (or #`\"double\"`).\nheights[complete.cases(heights)]\n\nRecall that you can use the typeof() function to find the type of your atomic vector.\nChallenge\n\n\nUsing this vector of heights in inches, create a new vector, heights_no_na, with the NAs removed.\nheights <- c(63, 69, 60, 65, NA, 68, 61, 70, 61, 59, 64, 69, 63, 63, NA, 72, 65, 64, 70, 63, 65)\n\nUse the function median() to calculate the median of the heights vector.\nUse R to figure out how many people in the set are taller than 67 inches.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nheights <- c(63, 69, 60, 65, NA, 68, 61, 70, 61, 59, 64, 69, 63, 63, NA, 72, 65, 64, 70, 63, 65)\n\n# 1.\nheights_no_na <- heights[!is.na(heights)]\n# or\nheights_no_na <- na.omit(heights)\n# or\nheights_no_na <- heights[complete.cases(heights)]\n\n# 2.\nmedian(heights, na.rm = TRUE)\n\n# 3.\nheights_above_67 <- heights_no_na[heights_no_na > 67]\nlength(heights_above_67)\n\n\n\n\n\n\n\nNow that we have learned how to write scripts, and the basics of R‚Äôs data structures, we are ready to start working with the Portal dataset we have been using in the other lessons, and learn about data frames.\n\nPage built on: üìÜ 2022-06-29 ‚Äí üï¢ 14:53:11"
  },
  {
    "objectID": "CONDUCT.html",
    "href": "CONDUCT.html",
    "title": "Centre for Applied Bioinformatics R Workshop",
    "section": "",
    "text": "As contributors and maintainers of this project, we pledge to respect all people who contribute through reporting issues, posting feature requests, updating documentation, submitting pull requests or patches, and other activities.\nWe are committed to making participation in this project a harassment-free experience for everyone, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, or religion.\nExamples of unacceptable behavior by participants include the use of sexual language or imagery, derogatory comments or personal attacks, trolling, public or private harassment, insults, or other unprofessional conduct.\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to our Code of Conduct. Project maintainers who do not follow the Code of Conduct may be removed from the project team.\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by following our reporting guidelines.\n\nPage built on: üìÜ 2022-06-28 ‚Äí üï¢ 17:22:48"
  },
  {
    "objectID": "04-visualization-ggplot2.html",
    "href": "04-visualization-ggplot2.html",
    "title": "Data visualization with ggplot2",
    "section": "",
    "text": "We start by loading the required packages. ggplot2 is included in the tidyverse package.\nIf not still in the workspace, load the data we saved in the previous lesson."
  },
  {
    "objectID": "04-visualization-ggplot2.html#plotting-with-ggplot2",
    "href": "04-visualization-ggplot2.html#plotting-with-ggplot2",
    "title": "Data visualization with ggplot2",
    "section": "Plotting with ggplot2\n",
    "text": "Plotting with ggplot2\n\nggplot2 is a plotting package that provides helpful commands to create complex plots from data in a data frame. It provides a more programmatic interface for specifying what variables to plot, how they are displayed, and general visual properties. Therefore, we only need minimal changes if the underlying data change or if we decide to change from a bar plot to a scatterplot. This helps in creating publication quality plots with minimal amounts of adjustments and tweaking.\nggplot2 refers to the name of the package itself. When using the package we use the function ggplot() to generate the plots, and so references to using the function will be referred to as ggplot() and the package as a whole as ggplot2\nggplot2 plots work best with data in the ‚Äòlong‚Äô format, i.e., a column for every variable, and a row for every observation. Well-structured data will save you lots of time when making figures with ggplot2\nggplot graphics are built layer by layer by adding new elements. Adding layers in this fashion allows for extensive flexibility and customization of plots.\nTo build a ggplot, we will use the following basic template that can be used for different types of plots:\nggplot(data = <DATA>, mapping = aes(<MAPPINGS>)) +  <GEOM_FUNCTION>()\n\nuse the ggplot() function and bind the plot to a specific data frame using the data argument\n\n\nggplot(data = surveys_complete)\n\n\ndefine an aesthetic mapping (using the aesthetic (aes) function), by selecting the variables to be plotted and specifying how to present them in the graph, e.g., as x/y positions or characteristics such as size, shape, color, etc.\n\n\nggplot(data = surveys_complete, mapping = aes(x = weight, y = hindfoot_length))\n\n\n\nadd ‚Äògeoms‚Äô ‚Äì graphical representations of the data in the plot (points, lines, bars). ggplot2 offers many different geoms; we will use some common ones today, including:\n\n\ngeom_point() for scatter plots, dot plots, etc.\n\ngeom_boxplot() for, well, boxplots!\n\ngeom_line() for trend lines, time series, etc.\n\n\n\nTo add a geom to the plot use + operator. Because we have two continuous variables, let‚Äôs use geom_point() first:\n\nggplot(data = surveys_complete, aes(x = weight, y = hindfoot_length)) +\n  geom_point()\n\n\n\n\nThe + in the ggplot2 package is particularly useful because it allows you to modify existing ggplot objects. This means you can easily set up plot ‚Äútemplates‚Äù and conveniently explore different types of plots, so the above plot can also be generated with code like this:\n\n# Assign plot to a variable\nsurveys_plot <- ggplot(data = surveys_complete,\n                       mapping = aes(x = weight, y = hindfoot_length))\n\n# Draw the plot\nsurveys_plot +\n    geom_point()\n\n\n\n\nNotes\n\nAnything you put in the ggplot() function can be seen by any geom layers that you add (i.e., these are universal plot settings). This includes the x- and y-axis you set up in aes().\nYou can also specify aesthetics for a given geom independently of the aesthetics defined globally in the ggplot() function.\nThe + sign used to add layers must be placed at the end of each line containing a layer. If, instead, the + sign is added in the line before the other layer, ggplot2 will not add the new layer and will return an error message.\nYou may notice that we sometimes reference ‚Äòggplot2‚Äô and sometimes ‚Äòggplot‚Äô. To clarify, ‚Äòggplot2‚Äô is the name of the most recent version of the package. However, any time we call the function itself, it‚Äôs just called ‚Äòggplot‚Äô.\nThe previous version of the ggplot2 package, called ggplot, which also contained the ggplot() function is now unsupported and has been removed from CRAN in order to reduce accidental installations and further confusion.\n\n\n# This is the correct syntax for adding layers\nsurveys_plot +\n  geom_point()\n\n# This will not add the new layer and will return an error message\nsurveys_plot\n  + geom_point()\n\n\nChallenge (optional)\nScatter plots can be useful exploratory tools for small datasets. For data sets with large numbers of observations, such as the surveys_complete data set, overplotting of points can be a limitation of scatter plots. One strategy for handling such settings is to use hexagonal binning of observations. The plot space is tessellated into hexagons. Each hexagon is assigned a color based on the number of observations that fall within its boundaries. To use hexagonal binning with ggplot2, first install the R package hexbin from CRAN:\n\ninstall.packages(\"hexbin\")\nlibrary(hexbin)\n\nThen use the geom_hex() function:\n\nsurveys_plot +\n geom_hex()\n\n\nWhat are the relative strengths and weaknesses of a hexagonal bin plot compared to a scatter plot? Examine the above scatter plot and compare it with the hexagonal bin plot that you created."
  },
  {
    "objectID": "04-visualization-ggplot2.html#building-your-plots-iteratively",
    "href": "04-visualization-ggplot2.html#building-your-plots-iteratively",
    "title": "Data visualization with ggplot2",
    "section": "Building your plots iteratively",
    "text": "Building your plots iteratively\nBuilding plots with ggplot2 is typically an iterative process. We start by defining the dataset we‚Äôll use, lay out the axes, and choose a geom:\n\nggplot(data = surveys_complete, aes(x = weight, y = hindfoot_length)) +\n    geom_point()\n\n\n\n\nThen, we start modifying this plot to extract more information from it. For instance, we can add transparency (alpha) to avoid overplotting:\n\nggplot(data = surveys_complete, aes(x = weight, y = hindfoot_length)) +\n    geom_point(alpha = 0.1)\n\n\n\n\nWe can also add colors for all the points:\n\nggplot(data = surveys_complete, mapping = aes(x = weight, y = hindfoot_length)) +\n    geom_point(alpha = 0.1, color = \"blue\")\n\n\n\n\nOr to color each species in the plot differently, you could use a vector as an input to the argument color. ggplot2 will provide a different color corresponding to different values in the vector. Here is an example where we color with species_id:\n\nggplot(data = surveys_complete, mapping = aes(x = weight, y = hindfoot_length)) +\n    geom_point(alpha = 0.1, aes(color = species_id))\n\n\n\n\n\nChallenge\nUse what you just learned to create a scatter plot of weight over species_id with the plot types showing in different colors. Is this a good way to show this type of data?\n\n\n\nAnswer\n\n\nggplot(data = surveys_complete,\n       mapping = aes(x = species_id, y = weight)) +\n   geom_point(aes(color = plot_type))"
  },
  {
    "objectID": "04-visualization-ggplot2.html#boxplot",
    "href": "04-visualization-ggplot2.html#boxplot",
    "title": "Data visualization with ggplot2",
    "section": "Boxplot",
    "text": "Boxplot\nWe can use boxplots to visualize the distribution of weight within each species:\n\nggplot(data = surveys_complete, mapping = aes(x = species_id, y = weight)) +\n    geom_boxplot()\n\n\n\n\nBy adding points to the boxplot, we can have a better idea of the number of measurements and of their distribution:\n\nggplot(data = surveys_complete, mapping = aes(x = species_id, y = weight)) +\n    geom_boxplot(alpha = 0) +\n    geom_jitter(alpha = 0.3, color = \"tomato\")\n\n\n\n\nNotice how the boxplot layer is behind the jitter layer? What do you need to change in the code to put the boxplot in front of the points such that it‚Äôs not hidden?\n\nChallenges\nBoxplots are useful summaries, but hide the shape of the distribution. For example, if there is a bimodal distribution, it would not be observed with a boxplot. An alternative to the boxplot is the violin plot (sometimes known as a beanplot), where the shape (of the density of points) is drawn.\n\nReplace the box plot with a violin plot; see geom_violin().\n\nIn many types of data, it is important to consider the scale of the observations. For example, it may be worth changing the scale of the axis to better distribute the observations in the space of the plot. Changing the scale of the axes is done similarly to adding/modifying other components (i.e., by incrementally adding commands). Try making these modifications:\n\nRepresent weight on the log10 scale; see scale_y_log10().\n\nSo far, we‚Äôve looked at the distribution of weight within species. Try making a new plot to explore the distribution of another variable within each species.\n\nCreate boxplot for hindfoot_length. Overlay the boxplot layer on a jitter layer to show actual measurements.\nAdd color to the data points on your boxplot according to the plot from which the sample was taken (plot_id).\n\n\n\nHint: Check the class for plot_id. Consider changing the class of plot_id from integer to factor. Why does this change how R makes the graph?"
  },
  {
    "objectID": "04-visualization-ggplot2.html#plotting-time-series-data",
    "href": "04-visualization-ggplot2.html#plotting-time-series-data",
    "title": "Data visualization with ggplot2",
    "section": "Plotting time series data",
    "text": "Plotting time series data\nLet‚Äôs calculate number of counts per year for each genus. First we need to group the data and count records within each group:\n\nyearly_counts <- surveys_complete %>%\n  count(year, genus)\n\nTimelapse data can be visualized as a line plot with years on the x-axis and counts on the y-axis:\n\nggplot(data = yearly_counts, aes(x = year, y = n)) +\n     geom_line()\n\n\n\n\nUnfortunately, this does not work because we plotted data for all the genera together. We need to tell ggplot to draw a line for each genus by modifying the aesthetic function to include group = genus:\n\nggplot(data = yearly_counts, aes(x = year, y = n, group = genus)) +\n    geom_line()\n\n\n\n\nWe will be able to distinguish genera in the plot if we add colors (using color also automatically groups the data):\n\nggplot(data = yearly_counts, aes(x = year, y = n, color = genus)) +\n    geom_line()"
  },
  {
    "objectID": "04-visualization-ggplot2.html#integrating-the-pipe-operator-with-ggplot2",
    "href": "04-visualization-ggplot2.html#integrating-the-pipe-operator-with-ggplot2",
    "title": "Data visualization with ggplot2",
    "section": "Integrating the pipe operator with ggplot2",
    "text": "Integrating the pipe operator with ggplot2\nIn the previous lesson, we saw how to use the pipe operator %>% to use different functions in a sequence and create a coherent workflow. We can also use the pipe operator to pass the data argument to the ggplot() function. The hard part is to remember that to build your ggplot, you need to use + and not %>%.\n\nyearly_counts %>%\n    ggplot(mapping = aes(x = year, y = n, color = genus)) +\n    geom_line()\n\n\n\n\nThe pipe operator can also be used to link data manipulation with consequent data visualization.\n\nyearly_counts_graph <- surveys_complete %>%\n    count(year, genus) %>%\n    ggplot(mapping = aes(x = year, y = n, color = genus)) +\n    geom_line()\n\nyearly_counts_graph"
  },
  {
    "objectID": "04-visualization-ggplot2.html#faceting",
    "href": "04-visualization-ggplot2.html#faceting",
    "title": "Data visualization with ggplot2",
    "section": "Faceting",
    "text": "Faceting\nggplot has a special technique called faceting that allows the user to split one plot into multiple plots based on a factor included in the dataset. We will use it to make a time series plot for each genus:\n\nggplot(data = yearly_counts, aes(x = year, y = n)) +\n    geom_line() +\n    facet_wrap(facets = vars(genus))\n\n\n\n\nNow we would like to split the line in each plot by the sex of each individual measured. To do that we need to make counts in the data frame grouped by year, genus, and sex:\n\n yearly_sex_counts <- surveys_complete %>%\n                      count(year, genus, sex)\n\nWe can now make the faceted plot by splitting further by sex using color (within a single plot):\n\nggplot(data = yearly_sex_counts, mapping = aes(x = year, y = n, color = sex)) +\n  geom_line() +\n  facet_wrap(facets =  vars(genus))\n\n\n\n\nWe can also facet both by sex and genus:\n\nggplot(data = yearly_sex_counts,\n       mapping = aes(x = year, y = n, color = sex)) +\n  geom_line() +\n  facet_grid(rows = vars(sex), cols =  vars(genus))\n\n\n\n\nYou can also organise the panels only by rows (or only by columns):\n\n# One column, facet by rows\nggplot(data = yearly_sex_counts,\n       mapping = aes(x = year, y = n, color = sex)) +\n  geom_line() +\n  facet_grid(rows = vars(genus))\n\n\n\n\n\n# One row, facet by column\nggplot(data = yearly_sex_counts,\n       mapping = aes(x = year, y = n, color = sex)) +\n  geom_line() +\n  facet_grid(cols = vars(genus))\n\n\n\n\nNote: ggplot2 before version 3.0.0 used formulas to specify how plots are faceted. If you encounter facet_grid/wrap(...) code containing ~, please read https://ggplot2.tidyverse.org/news/#tidy-evaluation."
  },
  {
    "objectID": "04-visualization-ggplot2.html#ggplot2-themes",
    "href": "04-visualization-ggplot2.html#ggplot2-themes",
    "title": "Data visualization with ggplot2",
    "section": "\nggplot2 themes",
    "text": "ggplot2 themes\nUsually plots with white background look more readable when printed. Every single component of a ggplot graph can be customized using the generic theme() function, as we will see below. However, there are pre-loaded themes available that change the overall appearance of the graph without much effort.\nFor example, we can change our previous graph to have a simpler white background using the theme_bw() function:\n\n ggplot(data = yearly_sex_counts,\n        mapping = aes(x = year, y = n, color = sex)) +\n     geom_line() +\n     facet_wrap(vars(genus)) +\n     theme_bw()\n\n\n\n\nIn addition to theme_bw(), which changes the plot background to white, ggplot2 comes with several other themes which can be useful to quickly change the look of your visualization. The complete list of themes is available at https://ggplot2.tidyverse.org/reference/ggtheme.html. theme_minimal() and theme_light() are popular, and theme_void() can be useful as a starting point to create a new hand-crafted theme.\nThe ggthemes package provides a wide variety of options.\n\nChallenge\nUse what you just learned to create a plot that depicts how the average weight of each species changes through the years.\n\n\n\nAnswer\n\n\nyearly_weight <- surveys_complete %>%\n                group_by(year, species_id) %>%\n                 summarize(avg_weight = mean(weight))\n\n#> `summarise()` has grouped output by 'year'. You can override using the\n#> `.groups` argument.\n\nggplot(data = yearly_weight, mapping = aes(x=year, y=avg_weight)) +\n   geom_line() +\n   facet_wrap(vars(species_id)) +\n   theme_bw()"
  },
  {
    "objectID": "04-visualization-ggplot2.html#customization",
    "href": "04-visualization-ggplot2.html#customization",
    "title": "Data visualization with ggplot2",
    "section": "Customization",
    "text": "Customization\nTake a look at the ggplot2 cheat sheet, and think of ways you could improve the plot.\nNow, let‚Äôs change names of axes to something more informative than ‚Äòyear‚Äô and ‚Äòn‚Äô and add a title to the figure:\n\nggplot(data = yearly_sex_counts, aes(x = year, y = n, color = sex)) +\n    geom_line() +\n    facet_wrap(vars(genus)) +\n    labs(title = \"Observed genera through time\",\n         x = \"Year of observation\",\n         y = \"Number of individuals\") +\n    theme_bw()\n\n\n\n\nThe axes have more informative names, but their readability can be improved by increasing the font size. This can be done with the generic theme() function:\n\nggplot(data = yearly_sex_counts, mapping = aes(x = year, y = n, color = sex)) +\n    geom_line() +\n    facet_wrap(vars(genus)) +\n    labs(title = \"Observed genera through time\",\n        x = \"Year of observation\",\n        y = \"Number of individuals\") +\n    theme_bw() +\n    theme(text=element_text(size = 16))\n\n\n\n\nNote that it is also possible to change the fonts of your plots. If you are on Windows, you may have to install the extrafont package, and follow the instructions included in the README for this package.\nAfter our manipulations, you may notice that the values on the x-axis are still not properly readable. Let‚Äôs change the orientation of the labels and adjust them vertically and horizontally so they don‚Äôt overlap. You can use a 90 degree angle, or experiment to find the appropriate angle for diagonally oriented labels. We can also modify the facet label text (strip.text) to italicize the genus names:\n\nggplot(data = yearly_sex_counts, mapping = aes(x = year, y = n, color = sex)) +\n    geom_line() +\n    facet_wrap(vars(genus)) +\n    labs(title = \"Observed genera through time\",\n        x = \"Year of observation\",\n        y = \"Number of individuals\") +\n    theme_bw() +\n    theme(axis.text.x = element_text(colour = \"grey20\", size = 12, angle = 90, hjust = 0.5, vjust = 0.5),\n                        axis.text.y = element_text(colour = \"grey20\", size = 12),\n                        strip.text = element_text(face = \"italic\"),\n                        text = element_text(size = 16))\n\n\n\n\nIf you like the changes you created better than the default theme, you can save them as an object to be able to easily apply them to other plots you may create:\n\ngrey_theme <- theme(axis.text.x = element_text(colour=\"grey20\", size = 12,\n                                               angle = 90, hjust = 0.5,\n                                               vjust = 0.5),\n                    axis.text.y = element_text(colour = \"grey20\", size = 12),\n                    text=element_text(size = 16))\n\nggplot(surveys_complete, aes(x = species_id, y = hindfoot_length)) +\n    geom_boxplot() +\n    grey_theme\n\n\n\n\n\nChallenge\nWith all of this information in hand, please take another five minutes to either improve one of the plots generated in this exercise or create a beautiful graph of your own. Use the RStudio ggplot2 cheat sheet for inspiration.\nHere are some ideas:\n\nSee if you can change the thickness of the lines.\nCan you find a way to change the name of the legend? What about its labels?\nTry using a different color palette (see https://www.cookbook-r.com/Graphs/Colors_(ggplot2)/)."
  },
  {
    "objectID": "04-visualization-ggplot2.html#arranging-plots",
    "href": "04-visualization-ggplot2.html#arranging-plots",
    "title": "Data visualization with ggplot2",
    "section": "Arranging plots",
    "text": "Arranging plots\nFaceting is a great tool for splitting one plot into multiple plots, but sometimes you may want to produce a single figure that contains multiple plots using different variables or even different data frames. The patchwork package allows us to combine separate ggplots into a single figure while keeping everything aligned properly. Like most R packages, we can install patchwork from CRAN, the R package repository:\n\ninstall.packages(\"patchwork\")\n\nAfter you have loaded the patchwork package you can use + to place plots next to each other, / to arrange them vertically, and plot_layout() to determine how much space each plot uses:\n\nlibrary(patchwork)\n\nplot_weight <- ggplot(data = surveys_complete, aes(x = species_id, y = weight)) +\n  geom_boxplot() +\n  labs(x = \"Species\", y = expression(log[10](Weight))) +\n  scale_y_log10()\n\nplot_count <- ggplot(data = yearly_counts, aes(x = year, y = n, color = genus)) +\n  geom_line() +\n  labs(x = \"Year\", y = \"Abundance\")\n\nplot_weight / plot_count + plot_layout(heights = c(3, 2))\n\n\n\n\nYou can also use parentheses () to create more complex layouts. There are many useful examples on the patchwork website"
  },
  {
    "objectID": "04-visualization-ggplot2.html#exporting-plots",
    "href": "04-visualization-ggplot2.html#exporting-plots",
    "title": "Data visualization with ggplot2",
    "section": "Exporting plots",
    "text": "Exporting plots\nAfter creating your plot, you can save it to a file in your favorite format. The Export tab in the Plot pane in RStudio will save your plots at low resolution, which will not be accepted by many journals and will not scale well for posters. The ggplot2 extensions website provides a list of packages that extend the capabilities of ggplot2, including additional themes.\nInstead, use the ggsave() function, which allows you to easily change the dimension and resolution of your plot by adjusting the appropriate arguments (width, height and dpi):\n\nmy_plot <- ggplot(data = yearly_sex_counts,\n                  aes(x = year, y = n, color = sex)) +\n    geom_line() +\n    facet_wrap(vars(genus)) +\n    labs(title = \"Observed genera through time\",\n        x = \"Year of observation\",\n        y = \"Number of individuals\") +\n    theme_bw() +\n    theme(axis.text.x = element_text(colour = \"grey20\", size = 12, angle = 90,\n                                     hjust = 0.5, vjust = 0.5),\n          axis.text.y = element_text(colour = \"grey20\", size = 12),\n          text = element_text(size = 16))\n\nggsave(\"name_of_file.png\", my_plot, width = 15, height = 10)\n\n## This also works for plots combined with patchwork\nplot_combined <- plot_weight / plot_count + plot_layout(heights = c(3, 2))\nggsave(\"plot_combined.png\", plot_combined, width = 10, dpi = 300)\n\nNote: The parameters width and height also determine the font size in the saved plot.\n\n\n\n\nPage built on: üìÜ 2022-06-28 ‚Äí üï¢ 17:23:19"
  },
  {
    "objectID": "03-dplyr.html#what-are-dplyr-and-tidyr",
    "href": "03-dplyr.html#what-are-dplyr-and-tidyr",
    "title": "Manipulating, analyzing and exporting data with tidyverse",
    "section": "What are dplyr and tidyr?",
    "text": "What are dplyr and tidyr?\nThe package dplyr provides helper tools for the most common data manipulation tasks. It is built to work directly with data frames, with many common tasks optimized by being written in a compiled language (C++). An additional feature is the ability to work directly with data stored in an external database. The benefits of doing this are that the data can be managed natively in a relational database, queries can be conducted on that database, and only the results of the query are returned.\nThis addresses a common problem with R in that all operations are conducted in-memory and thus the amount of data you can work with is limited by available memory. The database connections essentially remove that limitation in that you can connect to a database of many hundreds of GB, conduct queries on it directly, and pull back into R only what you need for analysis.\nThe package tidyr addresses the common problem of wanting to reshape your data for plotting and usage by different R functions. For example, sometimes we want data sets where we have one row per measurement. Other times we want a data frame where each measurement type has its own column, and rows are instead more aggregated groups (e.g., a time period, an experimental unit like a plot or a batch number). Moving back and forth between these formats is non-trivial, and tidyr gives you tools for this and more sophisticated data manipulation.\nTo learn more about dplyr and tidyr after the workshop, you may want to check out this handy data transformation with dplyr cheatsheet and this one about tidyr.\nAs before, we‚Äôll read in our data using the read_csv() function from the tidyverse package readr.\n\nsurveys <- read_csv(\"data_raw/portal_data_joined.csv\")\n\n#> Rows: 34786 Columns: 13\n#> ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#> Delimiter: \",\"\n#> chr (6): species_id, sex, genus, species, taxa, plot_type\n#> dbl (7): record_id, month, day, year, plot_id, hindfoot_length, weight\n#> \n#> ‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n#> ‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n## inspect the data\nstr(surveys)\n\n\n## preview the data\nview(surveys)\n\nNext, we‚Äôre going to learn some of the most common dplyr functions:\n\n\nselect(): subset columns\n\nfilter(): subset rows on conditions\n\nmutate(): create new columns by using information from other columns\n\ngroup_by() and summarize(): create summary statistics on grouped data\n\narrange(): sort results\n\ncount(): count discrete values"
  },
  {
    "objectID": "03-dplyr.html#selecting-columns-and-filtering-rows",
    "href": "03-dplyr.html#selecting-columns-and-filtering-rows",
    "title": "Manipulating, analyzing and exporting data with tidyverse",
    "section": "Selecting columns and filtering rows",
    "text": "Selecting columns and filtering rows\nTo select columns of a data frame, use select(). The first argument to this function is the data frame (surveys), and the subsequent arguments are the columns to keep.\n\nselect(surveys, plot_id, species_id, weight)\n\nTo select all columns except certain ones, put a ‚Äú-‚Äù in front of the variable to exclude it.\n\nselect(surveys, -record_id, -species_id)\n\nThis will select all the variables in surveys except record_id and species_id.\nTo choose rows based on a specific criterion, use filter():\n\nfilter(surveys, year == 1995)"
  },
  {
    "objectID": "03-dplyr.html#pipes",
    "href": "03-dplyr.html#pipes",
    "title": "Manipulating, analyzing and exporting data with tidyverse",
    "section": "Pipes",
    "text": "Pipes\nWhat if you want to select and filter at the same time? There are three ways to do this: use intermediate steps, nested functions, or pipes.\nWith intermediate steps, you create a temporary data frame and use that as input to the next function, like this:\n\nsurveys2 <- filter(surveys, weight < 5)\nsurveys_sml <- select(surveys2, species_id, sex, weight)\n\nThis is readable, but can clutter up your workspace with lots of objects that you have to name individually. With multiple steps, that can be hard to keep track of.\nYou can also nest functions (i.e.¬†one function inside of another), like this:\n\nsurveys_sml <- select(filter(surveys, weight < 5), species_id, sex, weight)\n\nThis is handy, but can be difficult to read if too many functions are nested, as R evaluates the expression from the inside out (in this case, filtering, then selecting).\nThe last option, pipes, are a recent addition to R. Pipes let you take the output of one function and send it directly to the next, which is useful when you need to do many things to the same dataset. Pipes in R look like %>% and are made available via the magrittr package, installed automatically with dplyr. If you use RStudio, you can type the pipe with Ctrl + Shift + M if you have a PC or Cmd + Shift + M if you have a Mac.\n\nsurveys %>%\n  filter(weight < 5) %>%\n  select(species_id, sex, weight)\n\nIn the above code, we use the pipe to send the surveys dataset first through filter() to keep rows where weight is less than 5, then through select() to keep only the species_id, sex, and weight columns. Since %>% takes the object on its left and passes it as the first argument to the function on its right, we don‚Äôt need to explicitly include the data frame as an argument to the filter() and select() functions any more.\nSome may find it helpful to read the pipe like the word ‚Äúthen.‚Äù For instance, in the example above, we took the data frame surveys, then we filtered for rows with weight < 5, then we selected columns species_id, sex, and weight. The dplyr functions by themselves are somewhat simple, but by combining them into linear workflows with the pipe we can accomplish more complex manipulations of data frames.\nIf we want to create a new object with this smaller version of the data, we can assign it a new name:\n\nsurveys_sml <- surveys %>%\n  filter(weight < 5) %>%\n  select(species_id, sex, weight)\n\nsurveys_sml\n\nNote that the final data frame is the leftmost part of this expression.\nChallenge\nUsing pipes, subset the surveys data to include animals collected before 1995 and retain only the columns year, sex, and weight.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nsurveys %>%\n    filter(year < 1995) %>%\n    select(year, sex, weight)\n\n\n\n\n\n\n\nMutate\nFrequently you‚Äôll want to create new columns based on the values in existing columns, for example to do unit conversions, or to find the ratio of values in two columns. For this we‚Äôll use mutate().\nTo create a new column of weight in kg:\n\nsurveys %>%\n  mutate(weight_kg = weight / 1000)\n\nYou can also create a second new column based on the first new column within the same call of mutate():\n\nsurveys %>%\n  mutate(weight_kg = weight / 1000,\n         weight_lb = weight_kg * 2.2)\n\nIf this runs off your screen and you just want to see the first few rows, you can use a pipe to view the head() of the data. (Pipes work with non-dplyr functions, too, as long as the dplyr or magrittr package is loaded).\n\nsurveys %>%\n  mutate(weight_kg = weight / 1000) %>%\n  head()\n\nThe first few rows of the output are full of NAs, so if we wanted to remove those we could insert a filter() in the chain:\n\nsurveys %>%\n  filter(!is.na(weight)) %>%\n  mutate(weight_kg = weight / 1000) %>%\n  head()\n\nis.na() is a function that determines whether something is an NA. The ! symbol negates the result, so we‚Äôre asking for every row where weight is not an NA.\nChallenge\nCreate a new data frame from the surveys data that meets the following criteria: contains only the species_id column and a new column called hindfoot_cm containing the hindfoot_length values (currently in mm) converted to centimeters. In this hindfoot_cm column, there are no NAs and all values are less than 3.\nHint: think about how the commands should be ordered to produce this data frame!\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nsurveys_hindfoot_cm <- surveys %>%\n    filter(!is.na(hindfoot_length)) %>%\n    mutate(hindfoot_cm = hindfoot_length / 10) %>%\n    filter(hindfoot_cm < 3) %>%\n    select(species_id, hindfoot_cm)\n\n\n\n\n\n\nSplit-apply-combine data analysis and the summarize() function\nMany data analysis tasks can be approached using the split-apply-combine paradigm: split the data into groups, apply some analysis to each group, and then combine the results. Key functions of dplyr for this workflow are group_by() and summarize().\nThe group_by() and summarize() functions\ngroup_by() is often used together with summarize(), which collapses each group into a single-row summary of that group. group_by() takes as arguments the column names that contain the categorical variables for which you want to calculate the summary statistics. So to compute the mean weight by sex:\n\nsurveys %>%\n  group_by(sex) %>%\n  summarize(mean_weight = mean(weight, na.rm = TRUE))\n\nYou may also have noticed that the output from these calls doesn‚Äôt run off the screen anymore. It‚Äôs one of the advantages of tbl_df over data frame.\nYou can also group by multiple columns:\n\nsurveys %>%\n  group_by(sex, species_id) %>%\n  summarize(mean_weight = mean(weight, na.rm = TRUE)) %>%\n  tail()\n\n#> `summarise()` has grouped output by 'sex'. You can override using the `.groups`\n#> argument.\n\n\nHere, we used tail() to look at the last six rows of our summary. Before, we had used head() to look at the first six rows. We can see that the sex column contains NA values because some animals had escaped before their sex and body weights could be determined. The resulting mean_weight column does not contain NA but NaN (which refers to ‚ÄúNot a Number‚Äù) because mean() was called on a vector of NA values while at the same time setting na.rm = TRUE. To avoid this, we can remove the missing values for weight before we attempt to calculate the summary statistics on weight. Because the missing values are removed first, we can omit na.rm = TRUE when computing the mean:\n\nsurveys %>%\n  filter(!is.na(weight)) %>%\n  group_by(sex, species_id) %>%\n  summarize(mean_weight = mean(weight))\n\n#> `summarise()` has grouped output by 'sex'. You can override using the `.groups`\n#> argument.\n\n\nHere, again, the output from these calls doesn‚Äôt run off the screen anymore. If you want to display more data, you can use the print() function at the end of your chain with the argument n specifying the number of rows to display:\n\nsurveys %>%\n  filter(!is.na(weight)) %>%\n  group_by(sex, species_id) %>%\n  summarize(mean_weight = mean(weight)) %>%\n  print(n = 15)\n\n#> `summarise()` has grouped output by 'sex'. You can override using the `.groups`\n#> argument.\n\n\nOnce the data are grouped, you can also summarize multiple variables at the same time (and not necessarily on the same variable). For instance, we could add a column indicating the minimum weight for each species for each sex:\n\nsurveys %>%\n  filter(!is.na(weight)) %>%\n  group_by(sex, species_id) %>%\n  summarize(mean_weight = mean(weight),\n            min_weight = min(weight))\n\n#> `summarise()` has grouped output by 'sex'. You can override using the `.groups`\n#> argument.\n\n\nIt is sometimes useful to rearrange the result of a query to inspect the values. For instance, we can sort on min_weight to put the lighter species first:\n\nsurveys %>%\n  filter(!is.na(weight)) %>%\n  group_by(sex, species_id) %>%\n  summarize(mean_weight = mean(weight),\n            min_weight = min(weight)) %>%\n  arrange(min_weight)\n\n#> `summarise()` has grouped output by 'sex'. You can override using the `.groups`\n#> argument.\n\n\nTo sort in descending order, we need to add the desc() function. If we want to sort the results by decreasing order of mean weight:\n\nsurveys %>%\n  filter(!is.na(weight)) %>%\n  group_by(sex, species_id) %>%\n  summarize(mean_weight = mean(weight),\n            min_weight = min(weight)) %>%\n  arrange(desc(mean_weight))\n\n#> `summarise()` has grouped output by 'sex'. You can override using the `.groups`\n#> argument.\n\n\nCounting\nWhen working with data, we often want to know the number of observations found for each factor or combination of factors. For this task, dplyr provides count(). For example, if we wanted to count the number of rows of data for each sex, we would do:\n\nsurveys %>%\n    count(sex)\n\nThe count() function is shorthand for something we‚Äôve already seen: grouping by a variable, and summarizing it by counting the number of observations in that group. In other words, surveys %>% count() is equivalent to:\n\nsurveys %>%\n    group_by(sex) %>%\n    summarise(count = n())\n\nFor convenience, count() provides the sort argument:\n\nsurveys %>%\n    count(sex, sort = TRUE)\n\nPrevious example shows the use of count() to count the number of rows/observations for one factor (i.e., sex). If we wanted to count combination of factors, such as sex and species, we would specify the first and the second factor as the arguments of count():\n\nsurveys %>%\n  count(sex, species)\n\nWith the above code, we can proceed with arrange() to sort the table according to a number of criteria so that we have a better comparison. For instance, we might want to arrange the table above in (i) an alphabetical order of the levels of the species and (ii) in descending order of the count:\n\nsurveys %>%\n  count(sex, species) %>%\n  arrange(species, desc(n))\n\nFrom the table above, we may learn that, for instance, there are 75 observations of the albigula species that are not specified for its sex (i.e.¬†NA).\n\nChallenge\n\nHow many animals were caught in each plot_type surveyed?\n\n\n\n\nAnswer\n\n\nsurveys %>%\n    count(plot_type)\n\n\n\n\nUse group_by() and summarize() to find the mean, min, and max hindfoot length for each species (using species_id). Also add the number of observations (hint: see ?n).\n\n\n\n\nAnswer\n\n\nsurveys %>%\n    filter(!is.na(hindfoot_length)) %>%\n    group_by(species_id) %>%\n    summarize(\n        mean_hindfoot_length = mean(hindfoot_length),\n        min_hindfoot_length = min(hindfoot_length),\n        max_hindfoot_length = max(hindfoot_length),\n        n = n()\n    )\n\n\n\n\nWhat was the heaviest animal measured in each year? Return the columns year, genus, species_id, and weight.\n\n\n\n\nAnswer\n\n\nsurveys %>%\n    filter(!is.na(weight)) %>%\n    group_by(year) %>%\n    filter(weight == max(weight)) %>%\n    select(year, genus, species, weight) %>%\n    arrange(year)\n\n\n\n\n\n\n\nReshaping with pivot_longer() and pivot_wider()\n\nIn the spreadsheet lesson, we discussed how to structure our data leading to the four rules defining a tidy dataset:\n\nEach variable has its own column\nEach observation has its own row\nEach value must have its own cell\nEach type of observational unit forms a table\n\nHere we examine the fourth rule: Each type of observational unit forms a table.\nIn surveys, the rows of surveys contain the values of variables associated with each record (the unit), values such as the weight or sex of each animal associated with each record. What if instead of comparing records, we wanted to compare the different mean weight of each genus between plots? (Ignoring plot_type for simplicity).\nWe‚Äôd need to create a new table where each row (the unit) is comprised of values of variables associated with each plot. In practical terms this means the values in genus would become the names of column variables and the cells would contain the values of the mean weight observed on each plot.\nHaving created a new table, it is therefore straightforward to explore the relationship between the weight of different genera within, and between, the plots. The key point here is that we are still following a tidy data structure, but we have reshaped the data according to the observations of interest: average genus weight per plot instead of recordings per date.\nThe opposite transformation would be to transform column names into values of a variable.\nWe can do both these of transformations with two tidyr functions, pivot_wider() and pivot_longer().\n\n\n\n\n\n\nDanger\n\n\n\nYou may find answers on stack-overflow and references to the reshape package and reshaep::melt() and the spread() and gather() functions that still exist inside of tidyr() but have now been superseded by pivot_wider() and pivot_longer() respectively.\nYou should use pivot_longer() and pivot_wider() in your own work as the older functions will eventually be removed from the tidyr package and your code will no longer run.\n\n\nPivoting Wider\npivot_wider() takes three principal arguments:\n\nthe data\nthe names_from column variable whose values will become new column names.\n\nthe values_from column variable whose values will fill the new column variables.\n\nFurther arguments include values_fill which, if set, fills in missing values with the value provided.\nLet‚Äôs use pivot_wider() to transform surveys to find the mean weight of each genus in each plot over the entire survey period. We use filter(), group_by() and summarise() to filter our observations and variables of interest, and create a new variable for the mean_weight.\n\nsurveys_gw <- surveys %>%\n  filter(!is.na(weight)) %>%\n  group_by(plot_id, genus) %>%\n  summarize(mean_weight = mean(weight))\n\n#> `summarise()` has grouped output by 'plot_id'. You can override using the\n#> `.groups` argument.\n\nstr(surveys_gw)\n\nThis yields surveys_gw where the observations for each plot are spread across multiple rows, 196 observations of 3 variables. Using spread() to key on genus with values from mean_weight this becomes 24 observations of 11 variables, one row for each plot.\n\nsurveys_spread <- surveys_gw %>%\n  pivot_wider(names_from = genus, values_from = mean_weight)\n\nstr(surveys_spread)\n\n\nWe could now plot comparisons between the weight of genera (one is called a genus, multiple are called genera) in different plots, although we may wish to fill in the missing values first.\n\nsurveys_gw %>%\n  pivot_wider(names_from = genus, values_from = mean_weight, values_fill = 0) %>%\n  head()\n\nPivoting Longer\nThe opposing situation could occur if we had been provided with data in the form of surveys_spread, where the genus names are column names, but we wish to treat them as values of a genus variable instead.\nIn this situation we are gathering the column names and turning them into a pair of new variables. One variable represents the column names as values, and the other variable contains the values previously associated with the column names.\ngather() takes four principal arguments:\n\nthe data\nthe key column variable we wish to create from column names.\nthe values column variable we wish to create and fill with values associated with the key.\nthe names of the columns we use to fill the key variable (or to drop).\n\nTo recreate surveys_gw from surveys_spread we would create a key called genus and value called mean_weight and use all columns except plot_id for the key variable. Here we exclude plot_id from being gather()ed.\n\nsurveys_gather <- surveys_spread %>%\n  pivot_longer(cols = -plot_id, values_to = \"mean_weight\", names_to = \"genus\")\n\nstr(surveys_gather)\n\n\nNote that now the NA genera are included in the re-gathered format. Spreading and then gathering can be a useful way to balance out a dataset so every replicate has the same composition.\nWe could also have used a specification for what columns to include. This can be useful if you have a large number of identifying columns, and it allows you to type less in order to specify what to gather than what to leave alone. And if the columns are directly adjacent, we don‚Äôt even need to list them all out - instead you can use the : operator!\n\nsurveys_spread %>%\n  pivot_longer(Baiomys:Spermophilus, values_to = \"mean_weight\", names_to = \"genus\") %>%\n  head()\n  \n# if you don't specify the column names, it will default to \"names\" and \"values\"\nsurveys_spread %>%\n  pivot_longer(Baiomys:Spermophilus) %>%\n  head()\n\n\nChallenge\n\nSpread the surveys data frame with year as columns, plot_id as rows, and the number of genera per plot as the values. You will need to summarize before reshaping, and use the function n_distinct() to get the number of unique genera within a particular chunk of data. It‚Äôs a powerful function! See ?n_distinct for more.\n\n\n\n\nAnswer\n\n\nsurveys_spread_genera <- surveys %>%\n  group_by(plot_id, year) %>%\n  summarize(n_genera = n_distinct(genus)) %>%\n  spread(year, n_genera)\n\n#> `summarise()` has grouped output by 'plot_id'. You can override using the\n#> `.groups` argument.\n\nhead(surveys_spread_genera)\n\n\n\n\nNow take that data frame and gather() it again, so each row is a unique plot_id by year combination.\n\n\n\n\nAnswer\n\n\nsurveys_spread_genera %>%\n  gather(\"year\", \"n_genera\", -plot_id)\n\n\n\n\nThe surveys data set has two measurement columns: hindfoot_length and weight. This makes it difficult to do things like look at the relationship between mean values of each measurement per year in different plot types. Let‚Äôs walk through a common solution for this type of problem. First, use gather() to create a dataset where we have a key column called measurement and a value column that takes on the value of either hindfoot_length or weight. Hint: You‚Äôll need to specify which columns are being gathered.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\nAnswer\n\n\nsurveys_long <- surveys %>%\n  gather(\"measurement\", \"value\", hindfoot_length, weight)\n\n\n\n\n\n\n\nWith this new data set, calculate the average of each measurement in each year for each different plot_type. Then spread() them into a data set with a column for hindfoot_length and weight. Hint: You only need to specify the key and value columns for spread().\n\n\n\n\nAnswer\n\n\nsurveys_long %>%\n  group_by(year, measurement, plot_type) %>%\n  summarize(mean_value = mean(value, na.rm=TRUE)) %>%\n  spread(measurement, mean_value)\n\n#> `summarise()` has grouped output by 'year', 'measurement'. You can override\n#> using the `.groups` argument."
  },
  {
    "objectID": "instructor-notes.html",
    "href": "instructor-notes.html",
    "title": "Instructor notes",
    "section": "",
    "text": "The data used for this lesson are in the figshare repository at: https://doi.org/10.6084/m9.figshare.1314459\nThis lesson uses mostly combined.csv. The 3 other csv files: plots.csv, species.csv and surveys.csv are only needed for the lesson on databases.\ncombined.csv is downloaded directly in the episode ‚ÄúStarting with Data‚Äù and does not need to be downloaded before hand. It however requires that there is a decent internet connection in the room where the workshop is being taught. To facilitate the download process, the chunk of code that includes the URL where the csv file lives, and where the file should go and be named is included in the code handout (see next paragraph). Using this approach ensures that the file will be where the lesson expects it to be, and teaches good/reproducible practice of automating the download. If the learners haven‚Äôt created the data/ directory and/or are not in the correct working directory, the download.file command will produce an error. Therefore, it is important to use the stickies at this point."
  },
  {
    "objectID": "instructor-notes.html#the-handout",
    "href": "instructor-notes.html#the-handout",
    "title": "Instructor notes",
    "section": "The handout",
    "text": "The handout\nThe code handout (a link to download it is also available on the top bar of the lesson website) is useful for Data Carpentry workshops. It includes an outline of the lesson content, the text for the challenges, the links for the files that need to be downloaded for the lesson, and pieces of code that may be difficult to type for learners with no programming experience/who are unfamiliar with R‚Äôs syntax. We encourage you to distribute it to the learners at the beginning of the lesson. As an instructor, we encourage you to do the live coding directly in this file, so the participants can follow along."
  },
  {
    "objectID": "instructor-notes.html#r-version",
    "href": "instructor-notes.html#r-version",
    "title": "Instructor notes",
    "section": "R Version",
    "text": "R Version\nWith the release of R 4.0.0 in early 2020, an important change has been made to R: The default for stringsAsFactors is now FALSE instead of TRUE. As a result, the read.csv() and data.frame() functions do not automatically convert character columns to factors anymore (you can read more about it in this post on the R developer blog).\nThis change should not cause any problems with this lesson, independent of whether R >4.0 is used or not, because it uses read_csv() from the tidyverse package throughout. Other than read.csv() from base R, read_csv() never converts character columns to factors, regardless of the R version.\nNevertheless, it is recommended that learners install a version of R ‚â•4.0.0, and instructors and helpers should be aware of this potential source of error."
  },
  {
    "objectID": "instructor-notes.html#rstudio-and-multiple-r-installs",
    "href": "instructor-notes.html#rstudio-and-multiple-r-installs",
    "title": "Instructor notes",
    "section": "RStudio and Multiple R Installs",
    "text": "RStudio and Multiple R Installs\nSome learners may have previous R installations. On Mac, if a new install is performed, the learner‚Äôs system will create a symbolic link, pointing to the new install as ‚ÄòCurrent.‚Äô Sometimes this process does not occur, and, even though a new R is installed and can be accessed via the R console, RStudio does not find it. The net result of this is that the learner‚Äôs RStudio will be running an older R install. This will cause package installations to fail. This can be fixed at the terminal. First, check for the appropriate R installation in the library;\nls -l /Library/Frameworks/R.framework/Versions/\nWe are currently using R 4.0.x. If it isn‚Äôt there, they will need to install it. If it is present, you will need to set the symbolic link to Current to point to the 4.0.x directory:\nln -s /Library/Frameworks/R.framework/Versions/3.6.x /Library/Frameworks/R.framework/Version/Current\nThen restart RStudio."
  },
  {
    "objectID": "instructor-notes.html#issues-with-fonts-on-macos",
    "href": "instructor-notes.html#issues-with-fonts-on-macos",
    "title": "Instructor notes",
    "section": "Issues with Fonts on MacOS",
    "text": "Issues with Fonts on MacOS\nOn older versions of MacOS, it may happen that axis labels do not show up when calling plot() (section ‚Äúrenaming factors‚Äù in ‚ÄúStarting with Data‚Äù). This issue might be due to the default font Arial being deactivated, so that R cannot find it. To resolve this issue, go to Finder, Search for Font Book and open it. Look for the Arial font and, if it is greyed out, turn it on.\nIf the problem occurs with ggplot2 plots, an alternative workaround is to change the default theme for the R session, so that ggplot uses a serif font. Since Arial is a sans-serif font, R will try to load a different font. This can be done with theme_update(text = element_text(family = \"serif\"))."
  },
  {
    "objectID": "instructor-notes.html#required-packages",
    "href": "instructor-notes.html#required-packages",
    "title": "Instructor notes",
    "section": "Required packages",
    "text": "Required packages\nSave yourself some aggrevation, and have everyone check and see if they can install all these packages before you start the first day. See the ‚ÄúPreparations‚Äù section on the homepage of the course website for package installation instructions.\nSometimes learners are unable to install the tidyverse package. In that case, they can try to install the individual packages that are actually needed:\ninstall.packages(c(\"readr\", \"lubridate\", \"dplyr\", \"tidyr\", \"ggplot2\", \"dbplyr\"))"
  },
  {
    "objectID": "instructor-notes.html#narrative",
    "href": "instructor-notes.html#narrative",
    "title": "Instructor notes",
    "section": "Narrative",
    "text": "Narrative\n\nBefore we start\n\nThe main goal here is to help the learners be comfortable with the RStudio interface. We use RStudio because it helps make using R more organized and user friendly.\nThe ‚ÄúWhy learning R?‚Äù section contains suggestions of what you could tell your learners about the benefits of learning R. However, it‚Äôs best if you can talk here about what has worked for you personally.\nGo very slowly in the ‚ÄúGetting setup section‚Äù. Make sure everyone is following along (remind learners to use the stickies). Plan with the helpers at this point to go around the room, and be available to help. It‚Äôs important to make sure that learners are in the correct working directory, and that they create a data_raw (all lowercase) subfolder.\nThe seeking help section is relatively long, and while it‚Äôs useful to demonstrate a couple of ways to get help from within R, you may want to mostly point the workshop participants to this useful reference so that they can refer to it after the workshop.\nIn the ‚Äúwhere to ask for help section?‚Äù, you may want to emphasize the first point about how workshops are a great way to create community of learners that can help each others during and after the workshop.\n\n\n\nIntro to R\n\nWhen going over the section on assignments, make sure to pause for at least 30 seconds when asking ‚ÄúWhat do you think is the current content of the object weight_lb? 126.5 or 220?‚Äù. For learners with no programming experience, this is a new and important concept.\nGiven that the concept of missing data is an important feature of the R language, it is worth spending enough time on it.\n\n\n\nStarting with data\nThe two main goals for this lessons are:\n\nTo make sure that learners are comfortable with working with data frames, and can use the bracket notation to select slices/columns\nTo expose learners to factors. Their behavior is not necessarily intuitive, and so it is important that they are guided through it the first time they are exposed to it. The content of the lesson should be enough for learners to avoid common mistakes with them.\nIf the learners are not familiar with the ecology terminology used in the data set, it might be a good idea to briefly review it here. Especially the terms genus and plot have caused some confusion to learners in the past. It might help to point out that the plural of genus is genera, and that plot_id and plot_type in the data set refer to the ID and type of a plot of land that was surveyed by the researchers in the study.\n\n\n\nManipulating data\n\nFor this lesson make sure that learners are comfortable using pipes.\nThere is also sometimes some confusion on what the arguments of group_by should be.\nThis lesson uses the tidyr package to reshape data for plotting\nAfter this lesson students should be familiar with the spread() and gather() functions available in tidyr\nWhile working with the example for mutate(), it is difficult to see the ‚Äúweight‚Äù columns on a zoomed in RStudio screen. Including a select() command to select the columns ‚Äúweight_kg‚Äù and ‚Äúweight_lb‚Äù makes it easier to view how the ‚Äúweight‚Äù columns are changed.\nIt is crucial that learners use the function read_csv() from tidyverse, not read.csv() from base R. Using the wrong function will cause unexpected results further down the line, especially in the section on working with factors.\nNote: If students end up with 30521 rows for surveys_complete instead of the expected 30463 rows at the end of the chapter, then they have likely used read.csv() and not read_csv() to import the data.\nWhen explaining view(), consider mentioning that is a function of the tibble package, and that the base function View() can also be used to view a data frame.\n\n\n\nVisualizing data\n\nThis lesson is a broad overview of ggplot2 and focuses on (1) getting familiar with the layering system of ggplot2, (2) using the argument group in the aes() function, (3) basic customization of the plots.\nIt maybe worthwhile to mention that we can also specify colors by color HEX code (http://colorbrewer2.org) ggplot(data = surveys_complete, mapping = aes(x = weight, y = hindfoot_length)) +         geom_point(alpha = 0.1, color = \"#FF0000\")\n\n\n\nR and SQL\n\nIdeally this lesson is best taught at the end of the workshop (as a capstone example) to illustrate how the tools covered can integrate with each others. Depending on the audience, and the pace of the workshop, it can be shown as a demonstration rather than a typically lesson.\nThe explanation of how dplyr‚Äôs verb syntax is translated into SQL statements, and the section on laziness are optional and don‚Äôt need to be taught in detail during a workshop. They can be useful after a workshop for learners interested in learning more about the topics or for instructors to answer questions from the workshop participants."
  },
  {
    "objectID": "instructor-notes.html#potential-issues-solutions",
    "href": "instructor-notes.html#potential-issues-solutions",
    "title": "Instructor notes",
    "section": "Potential issues & solutions",
    "text": "Potential issues & solutions\nAs it stands, the solutions to all the challenges are commented out in the Rmd files. If you want to double check your answer, you can look at the source code of the Rmd files on GitHub."
  },
  {
    "objectID": "instructor-notes.html#technical-tips-and-tricks",
    "href": "instructor-notes.html#technical-tips-and-tricks",
    "title": "Instructor notes",
    "section": "Technical Tips and Tricks",
    "text": "Technical Tips and Tricks\nShow how to use the ‚Äòzoom‚Äô button to blow up graphs without constantly resizing windows\nSometimes a package will not install, try a different CRAN mirror - Tools > Global Options > Packages > CRAN Mirror\nAlternatively you can go to CRAN and download the package and install from ZIP file - Tools > Install Packages > set to ‚Äòfrom Zip/TAR‚Äô\nIt is important that R, and the R packages be installed locally, not on a network drive. If a learner is using a machine with multiple users where their account is not based locally this can create a variety of issues (This often happens on university computers). Hopefully the learner will realize these issues before hand, but depending on the machine and how the IT folks that service the computer have things set up, it may be very difficult to impossible to make R work without their help.\nIf learners are having issues with one package, they may have issues with another. It is often easier to make sure they have all the necessary packages installed at one time, rather then deal with these issues over and over.\nIn lesson 2 starting with data, one might not have the appropriate folder ‚Äúdata_raw‚Äù in their working directory causing an error. This is a good time to go over reading an error, and a brief introduction of how to identify your working directory getwd() as well as setting your working directory setwd(\"/somedirectory\") and if needed creating a directory within your script dir.create(\"/some_new_directory\"), or simply creating it within a file explorer works if short on time."
  },
  {
    "objectID": "instructor-notes.html#other-resources",
    "href": "instructor-notes.html#other-resources",
    "title": "Instructor notes",
    "section": "Other Resources",
    "text": "Other Resources\nIf you encounter a problem during a workshop, feel free to contact the maintainers by email or open an issue.\nFor a more in-depth coverage of topics of the workshops, you may want to read ‚ÄúR for Data Science‚Äù by Hadley Wickham and Garrett Grolemund."
  }
]